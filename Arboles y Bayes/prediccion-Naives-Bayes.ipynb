{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import skopt\n",
    "import scipy\n",
    "from skopt.space import Real\n",
    "import category_encoders\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "import math\n",
    "\n",
    "PREDICCION_REAL = False\n",
    "MAXIMIZAR_HIPERPARAMETROS = False\n",
    "PARAMETROS = {\n",
    "    \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APERTURA DE ARCHIVO DE ARCHIVOS\n",
    "entrenamiento = pd.read_pickle(\"../Archivos/Entrenamiento_Grupo_0.pkl\")\n",
    "test = pd.read_pickle(\"../Archivos/Validacion_Grupo_0.pkl\").drop(columns = [\"Opportunity_ID\"])\n",
    "test_real = pd.read_pickle(\"../Archivos/Validacion_Grupo_0.pkl\")\n",
    "if PREDICCION_REAL:\n",
    "    test = pd.read_pickle(\"../Archivos/Test_Grupo_0.pkl\").drop(columns = [\"Opportunity_ID\"])\n",
    "    test_real = pd.read_pickle(\"../Archivos/Test_Grupo_0.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12140 entries, 0 to 12139\n",
      "Data columns (total 52 columns):\n",
      " #   Column                                                                 Non-Null Count  Dtype         \n",
      "---  ------                                                                 --------------  -----         \n",
      " 0   Opportunity_Name_Planned_Opportunity_Duration_mean                     12140 non-null  float64       \n",
      " 1   Opportunity_Name_Planned_Opportunity_Duration_min                      12140 non-null  float64       \n",
      " 2   Opportunity_Name_Planned_Time_Until_Deliver_mean                       12140 non-null  float64       \n",
      " 3   Product_Name_Planned_Opportunity_Duration_mean                         12140 non-null  float64       \n",
      " 4   Product_Name_Planned_Time_Until_Deliver_median                         12140 non-null  float64       \n",
      " 5   Account_Name_Planned_Opportunity_Duration_median                       12140 non-null  float64       \n",
      " 6   Account_Name_Planned_Time_Until_Deliver_mean                           12140 non-null  float64       \n",
      " 7   Product_Name_Planned_Time_Until_Deliver_std                            12140 non-null  float64       \n",
      " 8   Product_Name_Product_Amount_Deviation_of_Product_Family_rate_mean      12140 non-null  float64       \n",
      " 9   Opportunity_Name_Total_Amount(USD)_mean                                12140 non-null  float64       \n",
      " 10  Account_Name_Product_Amount_Deviation_of_Product_Family_rate_median    12140 non-null  float64       \n",
      " 11  Product_Name_Total_Amount(USD)_mean                                    12140 non-null  float64       \n",
      " 12  Opportunity_Name_Product_Amount_Deviation_of_Product_Family_rate_mean  12140 non-null  float64       \n",
      " 13  Bureaucratic_Code_Total_Taxable_Amount_max                             12140 non-null  float64       \n",
      " 14  Bureaucratic_Code_Delivery_Year_mean                                   12140 non-null  float64       \n",
      " 15  Bureaucratic_Code_Total_Amount_by_Product_Family_mean_std              12140 non-null  float64       \n",
      " 16  Bureaucratic_Code_Total_Products_Region_This_Quarter_median            12140 non-null  float64       \n",
      " 17  Bureaucratic_Code_Total_Product_Family_Region_Month_Change_mean        12140 non-null  float64       \n",
      " 18  Last_Modified_By_Opportunity_Total_Amount_Region_std_Ratio_max         12140 non-null  float64       \n",
      " 19  Bureaucratic_Code_Pricing, Delivery_Terms_Approved_std                 12140 non-null  float64       \n",
      " 20  Bureaucratic_Code_Bureaucratic_Code_0_Approved_mean                    12140 non-null  float64       \n",
      " 21  Product_Name_Planned_Deliver_Duration_std                              12140 non-null  float64       \n",
      " 22  Product_Name_Total_Taxable_Amount(USD)_std                             12140 non-null  float64       \n",
      " 23  Account_Name_Total_Amount(USD)_mean                                    12140 non-null  float64       \n",
      " 24  Bureaucratic_Code_Total_Products_Region_Last_Week_mean                 12140 non-null  float64       \n",
      " 25  Bureaucratic_Code_Opportunity_TRF_std                                  12140 non-null  float64       \n",
      " 26  Product_Name_Total_Amount_median                                       12140 non-null  float64       \n",
      " 27  Bureaucratic_Code_ASP_(converted)_max                                  12140 non-null  float64       \n",
      " 28  Bureaucratic_Code_Total_Taxable_Amount(USD)_std                        12140 non-null  float64       \n",
      " 29  Bureaucratic_Code_Opportunity_TRF_Region_avg_Ratio_std                 12140 non-null  float64       \n",
      " 30  Account_Name_Planned_Opportunity_Duration_min                          12140 non-null  float64       \n",
      " 31  Product_Name_Planned_Deliver_Duration_median                           12140 non-null  float64       \n",
      " 32  Last_Modified_By_Opportunity_ID_mean                                   12140 non-null  float64       \n",
      " 33  Bureaucratic_Code_Total_Products_Region_Last_Quarter_std               12140 non-null  float64       \n",
      " 34  Bureaucratic_Code_Planned_Opportunity_Duration_mean                    12140 non-null  float64       \n",
      " 35  Product_Name_Total_Taxable_Amount_mean                                 12140 non-null  float64       \n",
      " 36  Bureaucratic_Code_Total_Products_Region_This_Week_median               12140 non-null  float64       \n",
      " 37  Account_Name_Actual_Opportunity_Duration_min                           12140 non-null  float64       \n",
      " 38  Product_Name_Opportunity_TRF_Region_std_Ratio_std                      12140 non-null  float64       \n",
      " 39  Bureaucratic_Code_Total_Amount_by_Billing_Country_std_mean             12140 non-null  float64       \n",
      " 40  Product_Name_Opportunity_TRF_Region_avg_Ratio_mean                     12140 non-null  float64       \n",
      " 41  Account_Name_Total_Amount_by_Product_Family_mean_mean                  12140 non-null  float64       \n",
      " 42  Product_Name_TRF_mean                                                  12140 non-null  float64       \n",
      " 43  Account_Name_Product_Amount_Deviation_of_Product_Family_rate_min       12140 non-null  float64       \n",
      " 44  Last_Modified_By_Opportunity_TRF_Region_std_Ratio_max                  12140 non-null  float64       \n",
      " 45  Product_Name_Opportunity_TRF_std                                       12140 non-null  float64       \n",
      " 46  Account_Name_Month_std                                                 12140 non-null  float64       \n",
      " 47  Product_Name_Opportunity_Duration_by_Account_Type_std                  12140 non-null  float64       \n",
      " 48  Bureaucratic_Code_Pricing, Delivery_Terms_Approved_median              12140 non-null  float64       \n",
      " 49  Bureaucratic_Code_Month_median                                         12140 non-null  int64         \n",
      " 50  Stage                                                                  12140 non-null  int64         \n",
      " 51  Opportunity_Created_Date                                               12140 non-null  datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(49), int64(2)\n",
      "memory usage: 4.8 MB\n"
     ]
    }
   ],
   "source": [
    "entrenamiento.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILTRADO DE COLUMNAS - NO REMOVER STAGE O FECHA\n",
    "#fugas = ['ID','Opportunity_Name','Sales_Contract_No','Account_Name','Account_Owner','Opportunity_Owner','Last_Modified_By','Product_Family','Product_Name','ASP','ASP_(converted)']\n",
    "#'Total_Taxable_Amount'\n",
    "#columnas_fecha = ['Month','Last_Modified_Date','Account_Created_Date','Opportunity_Created_Date','Quote_Expiry_Date','Planned_Delivery_Start_Date','Planned_Delivery_End_Date']\n",
    "#entrenamiento = entrenamiento.drop(columns=fugas)\n",
    "#test = test.drop(columns=fugas)\n",
    "#test = test.drop(columns=columnas_fecha)\n",
    "#entrenamiento = entrenamiento.drop(columns=columnas_fecha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Last_Modified_Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\TP2-Orga\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Last_Modified_Date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-2a43011a2649>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumna\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumna\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'01/01/2000'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%m/%d/%Y'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mfecha_a_dias\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentrenamiento\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mfecha_a_dias\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-2a43011a2649>\u001b[0m in \u001b[0;36mfecha_a_dias\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfecha_a_dias\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcolumna\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcolumnas_fecha\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumna\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumna\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'01/01/2000'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'%m/%d/%Y'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mfecha_a_dias\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentrenamiento\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TP2-Orga\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\TP2-Orga\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Last_Modified_Date'"
     ]
    }
   ],
   "source": [
    "#FECHAS A DIAS\n",
    "\n",
    "columnas_fecha = ['Last_Modified_Date','Account_Created_Date','Opportunity_Created_Date','Planned_Delivery_Start_Date','Planned_Delivery_End_Date',\"Year-Month\"]\n",
    "def fecha_a_dias(x):\n",
    "    for columna in columnas_fecha:\n",
    "        x[columna] = x[columna].apply(lambda x : (pd.to_datetime(x) - pd.to_datetime('01/01/2000', format='%m/%d/%Y')).days)\n",
    "\n",
    "fecha_a_dias(entrenamiento)\n",
    "fecha_a_dias(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objetivo = (entrenamiento['Stage'] == 1).astype(int)\n",
    "entrenamiento = entrenamiento.drop(columns=['Stage'])\n",
    "columnas_category = list(entrenamiento.select_dtypes(include=['category']).columns)\n",
    "if 'Stage' in columnas_category : columnas_category.remove('Stage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not PREDICCION_REAL:\n",
    "    test_label = (test['Stage'] == 1).astype(int)\n",
    "    test = test.drop(columns=['Stage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categoricas_a_numericas(train,test,label,usar_label):\n",
    "    if (usar_label):\n",
    "        columnas_object = list(train.select_dtypes(include=['category']).columns)\n",
    "    else:\n",
    "        columnas_object = list(test.select_dtypes(include=['category']).columns)\n",
    "    if 'Stage' in columnas_object : columnas_object.remove('Stage')\n",
    "    ohe = category_encoders.cat_boost.CatBoostEncoder(cols = columnas_object,return_df = True)\n",
    "    ohe.fit(train,label)\n",
    "    if (usar_label):\n",
    "        columnas = ohe.transform(train,label)\n",
    "        for columna in columnas_object:\n",
    "            train[columna] = columnas[columna].copy()\n",
    "    else:\n",
    "        columnas = ohe.transform(test)\n",
    "        for columna in columnas_object:\n",
    "            test[columna] = columnas[columna].copy()\n",
    "categoricas_a_numericas(entrenamiento,test,objetivo,False)\n",
    "categoricas_a_numericas(entrenamiento,test,objetivo,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_nan(col):\n",
    "    mean = entrenamiento[col].mean()\n",
    "    entrenamiento[col] = entrenamiento[col].replace(np.NaN,mean)\n",
    "    mean = test[col].mean()\n",
    "    test[col] = test[col].replace(np.NaN,mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_inf(col):\n",
    "    entrenamiento[col] = entrenamiento[col].replace(math.inf,np.NaN)\n",
    "    test[col] = test[col].replace(math.inf,np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entrenamiento = entrenamiento.drop(columns = [\"Quote_Expiry_Date\",\"Total_Products_Region_Quarter_Change\"])\n",
    "#test = test.drop(columns = [\"Quote_Expiry_Date\",\"Total_Products_Region_Quarter_Change\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in entrenamiento.columns:\n",
    "    ent_null = entrenamiento.loc[entrenamiento[col] == np.inf]\n",
    "    if (ent_null[col].count() > 1000):\n",
    "        print(col)\n",
    "        print(ent_null[col].count())\n",
    "        entrenamiento = entrenamiento.drop(columns = [col])\n",
    "        test = test.drop(columns = [col])\n",
    "    if (0<ent_null[col].count() <= 1000):\n",
    "        print(col)\n",
    "        print(ent_null[col].count())\n",
    "        limpiar_inf(col)        \n",
    "for col in test.columns:\n",
    "    ent_null = test.loc[test[col] == np.inf]\n",
    "    if (ent_null[col].count() > 1000):\n",
    "        print(col)\n",
    "        print(ent_null[col].count())\n",
    "        entrenamiento = entrenamiento.drop(columns = [col])\n",
    "        test = test.drop(columns = [col])\n",
    "    if (0<ent_null[col].count() <= 1000):\n",
    "        print(col)\n",
    "        print(ent_null[col].count())\n",
    "        limpiar_inf(col)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in entrenamiento.columns:\n",
    "    ent_null = entrenamiento.loc[entrenamiento[col].isnull()]\n",
    "    ent_null = ent_null.replace(np.NaN,0)\n",
    "    if (ent_null[col].count() > 1000):\n",
    "        print(col)\n",
    "        print(ent_null[col].count())\n",
    "        entrenamiento = entrenamiento.drop(columns = [col])\n",
    "        test = test.drop(columns = [col])\n",
    "    if (0<ent_null[col].count() <= 1000):\n",
    "        print(col)\n",
    "        print(ent_null[col].count())\n",
    "        limpiar_nan(col)        \n",
    "for col in test.columns:\n",
    "    ent_null = test.loc[test[col].isnull()]\n",
    "    ent_null = ent_null.replace(np.NaN,0)\n",
    "    if (ent_null[col].count() > 1000):\n",
    "        print(col)\n",
    "        print(ent_null[col].count())\n",
    "        entrenamiento = entrenamiento.drop(columns = [col])\n",
    "        test = test.drop(columns = [col])\n",
    "    if (0<ent_null[col].count() <= 1000):\n",
    "        print(col)\n",
    "        print(ent_null[col].count())\n",
    "        limpiar_nan(col)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_usar = ['Opportunity_Name_Planned_Opportunity_Duration_mean',\n",
    "               'Opportunity_Name_Planned_Opportunity_Duration_min',\n",
    "               'Opportunity_Name_Planned_Time_Until_Deliver_mean',\n",
    "               'Product_Name_Planned_Opportunity_Duration_mean',\n",
    "               'Product_Name_Planned_Time_Until_Deliver_median',\n",
    "               'Account_Name_Planned_Opportunity_Duration_median',\n",
    "               'Account_Name_Planned_Time_Until_Deliver_mean',\n",
    "               'Product_Name_Planned_Time_Until_Deliver_std',\n",
    "               'Product_Name_Product_Amount_Deviation_of_Product_Family_rate_mean',\n",
    "               'Opportunity_Name_Total_Amount(USD)_mean',\n",
    "               'Account_Name_Product_Amount_Deviation_of_Product_Family_rate_median',\n",
    "               'Product_Name_Total_Amount(USD)_mean',\n",
    "               'Opportunity_Name_Product_Amount_Deviation_of_Product_Family_rate_mean',\n",
    "               'Bureaucratic_Code_Total_Taxable_Amount_max',\n",
    "               'Bureaucratic_Code_Delivery_Year_mean',\n",
    "               'Bureaucratic_Code_Total_Amount_by_Product_Family_mean_std',\n",
    "               'Bureaucratic_Code_Total_Products_Region_This_Quarter_median',\n",
    "               'Bureaucratic_Code_Total_Product_Family_Region_Month_Change_mean',\n",
    "               'Last_Modified_By_Opportunity_Total_Amount_Region_std_Ratio_max',\n",
    "               'Bureaucratic_Code_Pricing, Delivery_Terms_Approved_std',\n",
    "               'Bureaucratic_Code_Bureaucratic_Code_0_Approved_mean',\n",
    "               'Product_Name_Planned_Deliver_Duration_std',\n",
    "               'Product_Name_Total_Taxable_Amount(USD)_std',\n",
    "               'Account_Name_Total_Amount(USD)_mean',\n",
    "               'Bureaucratic_Code_Total_Products_Region_Last_Week_mean',\n",
    "               'Bureaucratic_Code_Opportunity_TRF_std',\n",
    "               'Product_Name_Total_Amount_median',\n",
    "               'Bureaucratic_Code_ASP_(converted)_max',\n",
    "               'Bureaucratic_Code_Total_Taxable_Amount(USD)_std',\n",
    "               'Bureaucratic_Code_Opportunity_TRF_Region_avg_Ratio_std',\n",
    "               'Account_Name_Planned_Opportunity_Duration_min',\n",
    "               'Product_Name_Planned_Deliver_Duration_median',\n",
    "               'Last_Modified_By_Opportunity_ID_mean',\n",
    "               'Bureaucratic_Code_Total_Products_Region_Last_Quarter_std',\n",
    "               'Bureaucratic_Code_Planned_Opportunity_Duration_mean',\n",
    "               'Product_Name_Total_Taxable_Amount_mean',\n",
    "               'Bureaucratic_Code_Total_Products_Region_This_Week_median',\n",
    "               'Account_Name_Actual_Opportunity_Duration_min',\n",
    "               'Product_Name_Opportunity_TRF_Region_std_Ratio_std',\n",
    "               'Bureaucratic_Code_Total_Amount_by_Billing_Country_std_mean',\n",
    "               'Product_Name_Opportunity_TRF_Region_avg_Ratio_mean',\n",
    "               'Account_Name_Total_Amount_by_Product_Family_mean_mean',\n",
    "               'Product_Name_TRF_mean',\n",
    "               'Account_Name_Product_Amount_Deviation_of_Product_Family_rate_min',\n",
    "               'Last_Modified_By_Opportunity_TRF_Region_std_Ratio_max',\n",
    "               'Product_Name_Opportunity_TRF_std',\n",
    "               'Account_Name_Month_std',\n",
    "               'Product_Name_Opportunity_Duration_by_Account_Type_std',\n",
    "               'Bureaucratic_Code_Pricing, Delivery_Terms_Approved_median',\n",
    "               'Bureaucratic_Code_Month_median']\n",
    "\n",
    "drop = list(entrenamiento.columns)\n",
    "for col in a_usar:\n",
    "    drop.remove(col)\n",
    "    \n",
    "entrenamiento = entrenamiento.drop(columns = drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(columns = drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenamiento.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GaussianNB(priors = [0.4,0.6],var_smoothing =0.01)\n",
    "\n",
    "model.fit(entrenamiento,objetivo)\n",
    "# make the prediction using the resulting model\n",
    "preds = model.predict_proba(test)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not PREDICCION_REAL:\n",
    "    #accuracy_score(test_label, [1])\n",
    "    print(skl.metrics.log_loss(test_label,[p[1] for p in preds]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(entrenamiento)\n",
    "accuracy_score(objetivo, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (PREDICCION_REAL):\n",
    "    preds = model.predict_proba(test)\n",
    "    resultados = test_real[['Opportunity_ID']].copy()\n",
    "    resultados['Target'] = pd.Series([p[1] for p in preds])\n",
    "    resultados = resultados.groupby('Opportunity_ID').mean()\n",
    "    resultados = resultados.reset_index()\n",
    "    #resultados['Target'] = resultados['Target'].apply(lambda x: int(x >= 0.5))    \n",
    "    resultados.to_csv(\"prediccion_naive_bayes.csv\", index=False)\n",
    "    resultados['Target'].value_counts()\n",
    "\n",
    "if not PREDICCION_REAL:\n",
    "    preds = model.predict_proba(test)\n",
    "    resultados = test_real[['Opportunity_ID']].copy()\n",
    "    print(resultados.count())\n",
    "    resultados['Target'] = pd.Series([p[1] for p in preds])\n",
    "    #resultados = resultados.groupby('Opportunity_ID').mean()\n",
    "    #resultados = resultados.reset_index()\n",
    "    print(resultados.count())\n",
    "    #resultados['Target'] = resultados['Target'].apply(lambda x: int(x >= 0.5))    \n",
    "    resultados.to_csv(\"prediccion_naive_bayes_val.csv\", index=False)\n",
    "    resultados['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not MAXIMIZAR_HIPERPARAMETROS): sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenamiento.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real\n",
    "from sklearn.model_selection import StratifiedKFold,GridSearchCV\n",
    "\n",
    "# Classifier\n",
    "bayes_cv_tuner = GridSearchCV(\n",
    "estimator = skl.naive_bayes.GaussianNB(),\n",
    "param_grid = {\n",
    "        \"var_smoothing\" : [i/10000 for i in range(1,1000)],\n",
    "        \"priors\" : [[i/10,1-i/10] for i in range(10)]\n",
    "},\n",
    "cv = skl.model_selection.TimeSeriesSplit(),\n",
    "n_jobs = 50,\n",
    "verbose = 1,\n",
    "refit = True,\n",
    "scoring = \"neg_log_loss\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def status_print(optim_result):\n",
    "    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n",
    "    # Get all the models tested so far in DataFrame format\n",
    "    all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n",
    "\n",
    "    # Get current parameters and the best parameters    \n",
    "    best_params = pd.Series(bayes_cv_tuner.best_params_)\n",
    "    print('Model #{}\\nBest ROC-AUC: {}\\nBest params: {}\\n'.format(\n",
    "        len(all_models),\n",
    "        np.round(bayes_cv_tuner.best_score_, 4),\n",
    "        bayes_cv_tuner.best_params_\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt.space import Real\n",
    "from sklearn.model_selection import StratifiedKFold,GridSearchCV\n",
    "columnas = ['Bureaucratic_Code',\n",
    " 'Account_Name',\n",
    " 'Opportunity_Name',\n",
    " 'Opportunity_Owner',\n",
    " 'Last_Modified_By',\n",
    " 'Product_Family',\n",
    " 'Product_Name',\n",
    " 'Opportunity_Name_Planned_Time_Until_Deliver_mean',\n",
    " 'Opportunity_Name_Planned_Opportunity_Duration_mean',\n",
    " 'Product_Name_Planned_Time_Until_Deliver_mean',\n",
    " 'Product_Name_Planned_Opportunity_Duration_mean',\n",
    " 'Territory',\n",
    " 'Account_Owner',\n",
    " 'Account_Type',\n",
    " 'Opportunity_Type',\n",
    " 'Planned_Opportunity_Duration',\n",
    " 'Bureaucratic_Code_ASP_(converted)_std',\n",
    " 'Bureaucratic_Code_Total_Amount_mean',\n",
    " 'Bureaucratic_Code_Total_Product_Family_Region_Last_Month_mean',\n",
    " 'Bureaucratic_Code_Total_Product_Family_Region_Last_Month_std',\n",
    " 'Bureaucratic_Code_Total_Products_Region_Last_Week_std',\n",
    " 'Bureaucratic_Code_Total_Products_Region_Last_Month_mean',\n",
    " 'Bureaucratic_Code_Planned_Deliver_Duration_mean',\n",
    " 'Bureaucratic_Code_Planned_Deliver_Duration_std',\n",
    " 'Bureaucratic_Code_Actual_Opportunity_Duration_std',\n",
    " 'Bureaucratic_Code_Planned_Time_Until_Deliver_mean',\n",
    " 'Bureaucratic_Code_Planned_Time_Until_Deliver_std',\n",
    " 'Bureaucratic_Code_Planned_Opportunity_Duration_mean',\n",
    " 'Bureaucratic_Code_Product_Amount_Deviation_of_Product_Family_rate_std',\n",
    " 'Bureaucratic_Code_Opportunity_Duration_Ratio_std',\n",
    " 'Bureaucratic_Code_Opportunity_Total_Amount_Region_avg_std',\n",
    " 'Bureaucratic_Code_Opportunity_TRF_Region_std_Ratio_std',\n",
    " 'Bureaucratic_Code_Opportunity_Duration_by_Account_Type_std',\n",
    " 'Bureaucratic_Code_ASP_by_Billing_Country_mean_std',\n",
    " 'Bureaucratic_Code_Opportunity_Duration_by_Product_Family_mean_mean',\n",
    " 'Bureaucratic_Code_Buro_Approved_by_Product_Family_std',\n",
    " 'Account_Name_Planned_Opportunity_Duration_mean',\n",
    " 'Opportunity_Type_Planned_Time_Until_Deliver_mean',\n",
    " 'Opportunity_Type_Opportunity_Duration_by_Account_Type_mean',\n",
    " 'Last_Modified_By_Planned_Time_Until_Deliver_mean']\n",
    "mejor_score = 10000\n",
    "mejor_col = list(entrenamiento.columns)\n",
    "mejor_param = \"\"\n",
    "j = 0\n",
    "for i in columnas[::-1]:\n",
    "    bayes_cv_tuner = GridSearchCV(\n",
    "    estimator = skl.naive_bayes.GaussianNB(),\n",
    "    param_grid = {\n",
    "            \"var_smoothing\" : [i/100 for i in range(1,1000)],\n",
    "            \"priors\" : [[i/10,1-i/10] for i in range(10)]\n",
    "    },\n",
    "    cv = skl.model_selection.TimeSeriesSplit(),\n",
    "    n_jobs = 50,\n",
    "    verbose = 1,\n",
    "    refit = True\n",
    "    )   \n",
    "    if (j < len(columnas) - 1):\n",
    "        print(i)\n",
    "        entrenamiento = entrenamiento.drop(columns = [i])\n",
    "        test = test.drop(columns = [i])\n",
    "    resultCAT = bayes_cv_tuner.fit(entrenamiento, objetivo)\n",
    "    print(bayes_cv_tuner.best_score_)\n",
    "    print(list(entrenamiento.columns))\n",
    "    if (bayes_cv_tuner.best_score_ < mejor_score):\n",
    "        print(j)\n",
    "        mejor_score = bayes_cv_tuner.best_score_\n",
    "        mejor_param = bayes_cv_tuner.best_params_\n",
    "        mejor_col = list(entrenamiento.columns)\n",
    "    j+=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mejor_col)\n",
    "print(mejor_score)\n",
    "print(mejor_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultCAT = bayes_cv_tuner.fit(entrenamiento, objetivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bayes_cv_tuner.best_score_)\n",
    "print(bayes_cv_tuner.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = bayes_cv_tuner.predict_proba(test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl.metrics.log_loss(test_label,[p[1] for p in preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(bayes_cv_tuner.cv_results_)\n",
    "res[\"mean_test_score\"] = -res[\"mean_test_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"param_priors_\"] = res[\"param_priors\"].transform(lambda x : x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_var = res.loc[res[\"param_priors_\"] == 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import style\n",
    "plt.plot(res_var.param_var_smoothing.values,res_var.mean_test_score.values)\n",
    "plt.title(\"Evolución del Log-Loss variando Var_Smoothing\")\n",
    "plt.xlabel(\"Var_Smoothing\")\n",
    "plt.ylabel(\"Log-Loss\")\n",
    "style.use(\"seaborn\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_priors = res.loc[res[\"param_var_smoothing\"] == 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_priors[\"param_priors_\"] = res_priors[\"param_priors\"].transform(lambda x : x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_priors = res_priors.loc[res_priors.param_priors_ >= 0.1]\n",
    "plt.plot(res_priors.param_priors_.values,res_priors.mean_test_score.values)\n",
    "plt.title(\"Evolución del Log-Loss variando Priors\")\n",
    "plt.xlabel(\"Priors\")\n",
    "plt.ylabel(\"Log-Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
