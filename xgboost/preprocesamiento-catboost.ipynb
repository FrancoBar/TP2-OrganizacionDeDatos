{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import math\n",
    "\n",
    "PREDICCION_REAL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APERTURA DE ARCHIVO DE ARCHIVOS\n",
    "entrenamiento_temp = pd.read_csv(\"../Train_TP2_Datos_2020-2C.csv\")\n",
    "entrenamiento_temp = entrenamiento_temp[( entrenamiento_temp['Stage'] == 'Closed Won') | ( entrenamiento_temp['Stage'] == 'Closed Lost')]\n",
    "entrenamiento_temp = entrenamiento_temp.loc[(entrenamiento_temp[\"ASP_Currency\"] == entrenamiento_temp[\"Total_Taxable_Amount_Currency\"])]\n",
    "entrenamiento_temp = entrenamiento_temp.loc[entrenamiento_temp[\"Total_Taxable_Amount\"] > 0]\n",
    "\n",
    "test = pd.read_csv(\"../Test_TP2_Datos_2020-2C.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FORMATO FECHAS\n",
    "\n",
    "#Respalda fecha, usada para separa entrenamiento y test\n",
    "entrenamiento_temp['Fecha'] = pd.to_datetime(entrenamiento_temp['Opportunity_Created_Date'])\n",
    "columnas_fecha = ['Month','Last_Modified_Date','Account_Created_Date','Opportunity_Created_Date','Quote_Expiry_Date','Planned_Delivery_Start_Date','Planned_Delivery_End_Date']\n",
    "\n",
    "def formato_fechas(x):\n",
    "    for columna in columnas_fecha:\n",
    "        x[columna] = pd.to_datetime(x[columna])\n",
    "        \n",
    "formato_fechas(entrenamiento_temp)\n",
    "if(PREDICCION_REAL): \n",
    "    formato_fechas(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIVISION ENTRE SET DE ENTRENAMIENTO Y SET DE TEST\n",
    "\n",
    "if(PREDICCION_REAL):\n",
    "    entrenamiento = entrenamiento_temp\n",
    "else:\n",
    "    entrenamiento = entrenamiento_temp.loc[entrenamiento_temp['Fecha'].dt.year <= 2017].copy()\n",
    "    test          = entrenamiento_temp.loc[entrenamiento_temp['Fecha'].dt.year > 2017].copy()\n",
    "    entrenamiento_label = (entrenamiento['Stage'] == 'Closed Won').astype(int)\n",
    "    test_label          = (test['Stage'] == 'Closed Won').astype(int)\n",
    "\n",
    "del entrenamiento_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIMPIEZA\n",
    "\n",
    "entrenamiento = entrenamiento.drop(columns=['ASP_(converted)_Currency','Quote_Type','Brand','Product_Type','Size','Product_Category_B','Price','Currency','Last_Activity','Actual_Delivery_Date','Prod_Category_A'])\n",
    "test = test.drop(columns=['ASP_(converted)_Currency','Quote_Type','Brand','Product_Type','Size','Product_Category_B','Price','Currency','Last_Activity','Actual_Delivery_Date','Prod_Category_A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUEVOS FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrego feature: Duracion de la oportunidad\n",
    "entrenamiento['Opportunity_Duration'] = (entrenamiento['Last_Modified_Date'] - entrenamiento['Opportunity_Created_Date']) / np.timedelta64(1, 'D')\n",
    "test['Opportunity_Duration'] = (test['Last_Modified_Date'] - test['Opportunity_Created_Date']) / np.timedelta64(1, 'D')\n",
    "\n",
    "#Agrego feature: Total_Amount_USD\n",
    "entrenamiento[\"Total_Amount_USD\"] = entrenamiento[\"Total_Amount\"] * entrenamiento[\"ASP_(converted)\"] / entrenamiento[\"ASP\"]\n",
    "test[\"Total_Amount_USD\"] = test[\"Total_Amount\"] * test[\"ASP_(converted)\"] / test[\"ASP\"]\n",
    "#Agrego feature: Total_Taxable_Amount_USD\n",
    "entrenamiento[\"Total_Taxable_Amount_USD\"] = entrenamiento[\"Total_Taxable_Amount\"] * entrenamiento[\"ASP_(converted)\"] / entrenamiento[\"ASP\"]\n",
    "test[\"Total_Taxable_Amount_USD\"] = test[\"Total_Taxable_Amount\"] * test[\"ASP_(converted)\"] / test[\"ASP\"]\n",
    "#Agrego feature: Total_Amount_sobre_Total_Taxable_Amount\n",
    "entrenamiento[\"Total_Amount_sobre_Total_Taxable_Amount\"] = entrenamiento[\"Total_Amount_USD\"] / entrenamiento[\"Total_Taxable_Amount_USD\"]\n",
    "test[\"Total_Amount_sobre_Total_Taxable_Amount\"] = test[\"Total_Amount_USD\"] / test[\"Total_Taxable_Amount_USD\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\pandas\\core\\series.py:679: RuntimeWarning: invalid value encountered in sign\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#FEATURE - Duracion por familia\n",
    "df_familia = entrenamiento[['Stage','Region','Territory','Product_Family','Planned_Delivery_Start_Date']]\n",
    "df_familia = df_familia[df_familia['Stage'] == 'Closed Won']\n",
    "df_familia = df_familia.groupby(['Product_Family'])['Planned_Delivery_Start_Date'].agg(['max','min']).reset_index()\n",
    "df_familia['Duracion_Familia'] = (df_familia['max'] - df_familia['min']).dt.days\n",
    "entrenamiento = entrenamiento.merge(df_familia[['Product_Family','Duracion_Familia','max']],on='Product_Family',how='left')\n",
    "entrenamiento['Duracion_Familia'] =  (entrenamiento['Planned_Delivery_Start_Date'] - entrenamiento['max']).dt.days - entrenamiento['Duracion_Familia']\n",
    "entrenamiento['Duracion_Familia'].replace(np.nan,0)\n",
    "entrenamiento['Duracion_Familia'] =  np.sign(entrenamiento['Duracion_Familia'])\n",
    "entrenamiento = entrenamiento.drop(columns=['max'])\n",
    "test = test.merge(entrenamiento[['Product_Family','Duracion_Familia']].drop_duplicates(subset=['Product_Family']),left_on='Product_Family',right_on='Product_Family',how='left')\n",
    "\n",
    "#FEATURE - Duracion por region\n",
    "df_region = entrenamiento[['Stage','Region','Territory','Planned_Delivery_Start_Date']]\n",
    "df_region = df_region[df_region['Stage'] == 'Closed Won']\n",
    "df_region = df_region.groupby(['Region'])['Planned_Delivery_Start_Date'].agg(['max','min']).reset_index()\n",
    "df_region['Duracion_Region'] = (df_region['max'] - df_region['min']).dt.days\n",
    "entrenamiento = entrenamiento.merge(df_region[['Region','Duracion_Region','max']],on='Region',how='left')\n",
    "entrenamiento['Duracion_Region'] =  (entrenamiento['Planned_Delivery_Start_Date'] - entrenamiento['max']).dt.days - entrenamiento['Duracion_Region']\n",
    "entrenamiento['Duracion_Region'].replace(np.nan,0)\n",
    "entrenamiento['Duracion_Region'] =  np.sign(entrenamiento['Duracion_Region'])\n",
    "entrenamiento = entrenamiento.drop(columns=['max'])\n",
    "test = test.merge(entrenamiento[['Region','Duracion_Region']].drop_duplicates(subset=['Region']),left_on='Region',right_on='Region',how='left')\n",
    "\n",
    "#FEATURE - Duracion por territory\n",
    "df_territorio = entrenamiento[['Stage','Territory','Planned_Delivery_Start_Date']]\n",
    "df_territorio = df_territorio[df_territorio['Stage'] == 'Closed Won']\n",
    "df_territorio = df_territorio.groupby(['Territory'])['Planned_Delivery_Start_Date'].agg(['max','min']).reset_index()\n",
    "df_territorio['Duracion_Territory'] = (df_territorio['max'] - df_territorio['min']).dt.days\n",
    "entrenamiento = entrenamiento.merge(df_territorio[['Territory','Duracion_Territory','max']],on='Territory',how='left')\n",
    "entrenamiento['Duracion_Territory'] =  (entrenamiento['Planned_Delivery_Start_Date'] - entrenamiento['max']).dt.days - entrenamiento['Duracion_Territory']\n",
    "entrenamiento['Duracion_Territory'].replace(np.nan,0)\n",
    "entrenamiento['Duracion_Territory'] =  np.sign(entrenamiento['Duracion_Territory'])\n",
    "entrenamiento = entrenamiento.drop(columns=['max'])\n",
    "test = test.merge(entrenamiento[['Territory','Duracion_Territory']].drop_duplicates(subset=['Territory']),left_on='Territory',right_on='Territory',how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FECHAS A DIAS\n",
    "def fecha_a_dias(x):\n",
    "    for columna in columnas_fecha:\n",
    "        x[columna] = x[columna].apply(lambda x : (x - pd.to_datetime('01/01/2000', format='%m/%d/%Y')).days)\n",
    "\n",
    "fecha_a_dias(entrenamiento)\n",
    "fecha_a_dias(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CATEGORICAS A NUMERICAS - PROMEDIO\n",
    "\"\"\"Se debe pasar train y test ordenados \"\"\"\n",
    "def expansion_mean_encoding(columnas_categoricas,train,test,label):\n",
    "    #Dividimos el dataset de entrenamiento en features y labels\n",
    "    #Armo un df extra que me ayudara para codificar las categoricas.\n",
    "    #x_y_train = filtrado.iloc[:-test_rows]\n",
    "    #x_train = x_y_train.drop('Stage', axis=1)\n",
    "    #y_train = x_y_train['Stage'].to_frame()\n",
    "    #x_test = filtrado.iloc[-test_rows:].drop('Stage', axis=1)\n",
    "    #y_test = filtrado.iloc[-test_rows:]['Stage'].to_frame()\n",
    "\n",
    "    #En el set de train.\n",
    "    #columnas_categoricas = x_train.select_dtypes(include='category').columns\n",
    "\n",
    "    codificaciones = dict()\n",
    "\n",
    "    for col in columnas_categoricas:\n",
    "        last_one = train.groupby(col).tail(1)\n",
    "        for (idx, reg) in zip(last_one[col].index, last_one[col].values):\n",
    "            codificaciones[reg] = (col, idx)\n",
    "        cumulative_sum = train.groupby(col)[label].cumsum() - train[label]\n",
    "        cumulative_count = train.groupby(col).cumcount()\n",
    "        train[col] = cumulative_sum/cumulative_count\n",
    "\n",
    "    #Llenamos los NaN generados por cumsum con ceros.\n",
    "    train.fillna(0,inplace = True)\n",
    "\n",
    "    #Guardamos la codificacion de cada categoria segun su nombre.\n",
    "    for k, v in codificaciones.items():\n",
    "        col = v[0]\n",
    "        idx = v[1]\n",
    "        codificaciones[k] = train.loc[idx, col]\n",
    "    \n",
    "    # Utilizo las ultimas codificaciones de cada categoria del train set para codificar el test set.\n",
    "    # Para eso utilizo el diccionario de codificaciones.\n",
    "\n",
    "    #columnas_categoricas = x_test.select_dtypes(include='category').columns\n",
    "\n",
    "    for col in columnas_categoricas:\n",
    "        test[col] = test[col].astype(object)\n",
    "        for (idx, reg) in zip(test[col].index, test[col]):\n",
    "            if (reg in codificaciones):\n",
    "                test.loc[idx, col] = codificaciones[reg]\n",
    "            else:\n",
    "                #Codifico como cero, se puede mejorar\n",
    "                test.loc[idx, col] = 0\n",
    "        test[col] = test[col].astype(float)\n",
    "        \n",
    "columnas_categoricas = list(entrenamiento.select_dtypes(include=['object']).columns)\n",
    "if 'Stage' in columnas_categoricas : columnas_categoricas.remove('Stage')\n",
    "entrenamiento[\"label\"] = (entrenamiento['Stage'] == 'Closed Won').astype(int)\n",
    "entrenamiento.sort_values(\"Fecha\")\n",
    "expansion_mean_encoding(columnas_categoricas,entrenamiento,test,\"label\")\n",
    "entrenamiento = entrenamiento.drop(columns='label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def mean_encoding(train,test,col_group,col_mean,operacion):\n",
    "    \n",
    "    codificaciones = dict()\n",
    "    nombre_col = col_group + \"_\" + col_mean + \"_\" + operacion\n",
    "\n",
    "    last_one = train.groupby(col_group).tail(1)\n",
    "    for (idx, reg) in zip(last_one[col_group].index, last_one[col_group].values):\n",
    "        codificaciones[reg] = (nombre_col, idx)\n",
    "\n",
    "    train[nombre_col] = train.groupby(col_group)[col_mean].transform(operacion)    \n",
    "\n",
    "    #Llenamos los NaN generados por cumsum con ceros.\n",
    "    train.fillna(0,inplace = True)\n",
    "\n",
    "    #Guardamos la codificacion de cada categoria segun su nombre.\n",
    "    for k, v in codificaciones.items():\n",
    "        col = v[0]\n",
    "        idx = v[1]\n",
    "        codificaciones[k] = train.loc[idx, col]\n",
    "    \n",
    "    # Utilizo las ultimas codificaciones de cada categoria del train set para codificar el test set.\n",
    "    # Para eso utilizo el diccionario de codificaciones.\n",
    "\n",
    "    #columnas_categoricas = x_test.select_dtypes(include='category').columns\n",
    "\n",
    "    test[nombre_col] = test[col_group].astype(object)\n",
    "    for (idx, reg) in zip(test[nombre_col].index, test[nombre_col]):\n",
    "        if (reg in codificaciones):\n",
    "            test.loc[idx, nombre_col] = codificaciones[reg]\n",
    "        else:\n",
    "            #Codifico como cero, se puede mejorar\n",
    "            test.loc[idx, nombre_col] = 0\n",
    "    test[nombre_col] = test[nombre_col].astype(float)\n",
    "\n",
    "    \n",
    "\n",
    "columnas_cat = [\"Region\",\"Territory\",\"Bureaucratic_Code\",\"Billing_Country\",\"Account_Type\",\"Opportunity_Type\",\"Delivery_Terms\",\"Last_Modified_By\",\"Product_Family\",\"Product_Name\",\"ASP_Currency\"]\n",
    "\n",
    "columnas_num = [\"Pricing, Delivery_Terms_Quote_Appr\",\"Pricing, Delivery_Terms_Approved\",\"Bureaucratic_Code_0_Approval\",\"Bureaucratic_Code_0_Approved\",\"Submitted_for_Approval\",\"ASP\",\"ASP_(converted)\",\"TRF\",\"Total_Amount_USD\",\"Total_Taxable_Amount_USD\",\"Opportunity_Duration\"]\n",
    "i = 0\n",
    "for col_cat in columnas_cat:\n",
    "    for col_num in columnas_num:\n",
    "        print(i)\n",
    "        i+= 1\n",
    "        mean_encoding(entrenamiento,test,col_cat,col_num,\"mean\")\n",
    "        mean_encoding(entrenamiento,test,col_cat,col_num,\"std\")\n",
    "\n",
    "def encoding_categorico(train,test,col_group,col_mean):\n",
    "    \n",
    "    codificaciones = dict()\n",
    "\n",
    "    last_one = train.groupby(col_group).tail(1)\n",
    "    for (idx, reg) in zip(last_one[col_group].index, last_one[col_group].values):\n",
    "        codificaciones[reg] = (col_group + \"_\" + col_mean, idx)\n",
    "\n",
    "    train[col_group + \"_\" + col_mean] = train.groupby(col_group)[col_mean].unique()    \n",
    "\n",
    "    #Llenamos los NaN generados por cumsum con ceros.\n",
    "    train.fillna(0,inplace = True)\n",
    "\n",
    "    #Guardamos la codificacion de cada categoria segun su nombre.\n",
    "    for k, v in codificaciones.items():\n",
    "        col = v[0]\n",
    "        idx = v[1]\n",
    "        codificaciones[k] = train.loc[idx, col]\n",
    "    \n",
    "    # Utilizo las ultimas codificaciones de cada categoria del train set para codificar el test set.\n",
    "    # Para eso utilizo el diccionario de codificaciones.\n",
    "\n",
    "    #columnas_categoricas = x_test.select_dtypes(include='category').columns\n",
    "\n",
    "    test[col_group + \"_\" + col_mean] = test[col_group].astype(object)\n",
    "    for (idx, reg) in zip(test[col_group + \"_\" + col_mean].index, test[col_group + \"_\" + col_mean]):\n",
    "        if (reg in codificaciones):\n",
    "            test.loc[idx, col_group + \"_\" + col_mean] = codificaciones[reg]\n",
    "        else:\n",
    "            #Codifico como cero, se puede mejorar\n",
    "            test.loc[idx, col_group + \"_\" + col_mean] = 0\n",
    "    test[col_group + \"_\" + col_mean] = test[col_group + \"_\" + col_mean].astype(float)\n",
    "\n",
    "for col1,col2 in list(permutations(columnas_cat,2)):\n",
    "    encoding_categorico(entrenamiento,test,col1,col2)\n",
    "    encoding_categorico(entrenamiento.copy(),test_prueba,col1,col2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CATEGORICAS A NUMERICAS  - ORDINAL\n",
    "def categoricas_a_numericas(x):\n",
    "    ohe = skl.preprocessing.OrdinalEncoder()\n",
    "    columnas_object = list(x.select_dtypes(include=['object']).columns)\n",
    "    if 'Stage' in columnas_object : columnas_object.remove('Stage')\n",
    "    for columna in columnas_object:\n",
    "        copia = x[[columna]].copy().dropna()\n",
    "        df_temp = pd.DataFrame(ohe.fit_transform(copia)).astype('int32')\n",
    "        df_temp.columns = [columna]\n",
    "        x[columna] = df_temp[columna]\n",
    "\n",
    "categoricas_a_numericas(entrenamiento)\n",
    "categoricas_a_numericas(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Quote_Expiry_Date', 'ASP', 'ASP_(converted)', 'Planned_Delivery_End_Date', 'Total_Amount', 'Total_Taxable_Amount', 'Opportunity_Duration', 'Total_Amount_USD', 'Total_Taxable_Amount_USD', 'Total_Amount_sobre_Total_Taxable_Amount', 'Duracion_Familia', 'Duracion_Territory']\n",
      "['Quote_Expiry_Date', 'ASP', 'ASP_(converted)', 'Planned_Delivery_End_Date', 'Total_Amount', 'Total_Taxable_Amount', 'Opportunity_Duration', 'Total_Amount_USD', 'Total_Taxable_Amount_USD', 'Total_Amount_sobre_Total_Taxable_Amount', 'Duracion_Familia', 'Duracion_Territory']\n"
     ]
    }
   ],
   "source": [
    "def convertir_a_int(x):\n",
    "    columnas_float = list(x.select_dtypes(include=[np.float]).columns)\n",
    "    print(columnas_float)\n",
    "    for columna in columnas_float:\n",
    "        x.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "        copia = x[[columna]].copy().dropna(how=\"all\")\n",
    "        x[columna] = (copia[columna]*100).astype(int)\n",
    "\n",
    "#entrenamiento = entrenamiento.loc[entrenamiento[\"Opportunity_Duration\"] != math.inf]\n",
    "#test = test.loc[test[\"Opportunity_Duration\"] != math.inf]\n",
    "convertir_a_int(entrenamiento)\n",
    "convertir_a_int(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#SUAVIZADO DE DISCREPANCIAS PARA EVITAR OVERFITTING\n",
    "\n",
    "for columna in columnas_fecha:\n",
    "    entrenamiento[columna] = np.round(entrenamiento[columna].apply(np.log10))\n",
    "    test[columna] =  np.round(test[columna].apply(np.log10))\n",
    "    \n",
    "entrenamiento['Total_Taxable_Amount'] = np.round(entrenamiento['Total_Taxable_Amount'].apply(np.log10))\n",
    "test['Total_Taxable_Amount'] =  np.round(test['Total_Taxable_Amount'].apply(np.log10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop('Fecha',1)\n",
    "entrenamiento = entrenamiento.drop('Fecha',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4430 entries, 0 to 4429\n",
      "Data columns (total 49 columns):\n",
      " #   Column                                   Non-Null Count  Dtype         \n",
      "---  ------                                   --------------  -----         \n",
      " 0   ID                                       4430 non-null   int64         \n",
      " 1   Region                                   4430 non-null   object        \n",
      " 2   Territory                                4430 non-null   object        \n",
      " 3   Pricing, Delivery_Terms_Quote_Appr       4430 non-null   int64         \n",
      " 4   Pricing, Delivery_Terms_Approved         4430 non-null   int64         \n",
      " 5   Bureaucratic_Code_0_Approval             4430 non-null   int64         \n",
      " 6   Bureaucratic_Code_0_Approved             4430 non-null   int64         \n",
      " 7   Submitted_for_Approval                   4430 non-null   int64         \n",
      " 8   Bureaucratic_Code                        4430 non-null   object        \n",
      " 9   Account_Created_Date                     4430 non-null   int64         \n",
      " 10  Source                                   4430 non-null   object        \n",
      " 11  Billing_Country                          4430 non-null   object        \n",
      " 12  Account_Name                             4430 non-null   object        \n",
      " 13  Opportunity_Name                         4430 non-null   object        \n",
      " 14  Opportunity_ID                           4430 non-null   int64         \n",
      " 15  Sales_Contract_No                        4430 non-null   object        \n",
      " 16  Account_Owner                            4430 non-null   object        \n",
      " 17  Opportunity_Owner                        4430 non-null   object        \n",
      " 18  Account_Type                             4430 non-null   object        \n",
      " 19  Opportunity_Type                         4430 non-null   object        \n",
      " 20  Delivery_Terms                           4430 non-null   object        \n",
      " 21  Opportunity_Created_Date                 4430 non-null   int64         \n",
      " 22  Quote_Expiry_Date                        2916 non-null   float64       \n",
      " 23  Last_Modified_Date                       4430 non-null   int64         \n",
      " 24  Last_Modified_By                         4430 non-null   object        \n",
      " 25  Product_Family                           4430 non-null   object        \n",
      " 26  Product_Name                             4430 non-null   object        \n",
      " 27  ASP_Currency                             4430 non-null   object        \n",
      " 28  ASP                                      3833 non-null   float64       \n",
      " 29  ASP_(converted)                          3833 non-null   float64       \n",
      " 30  Planned_Delivery_Start_Date              4430 non-null   int64         \n",
      " 31  Planned_Delivery_End_Date                4410 non-null   float64       \n",
      " 32  Month                                    4430 non-null   int64         \n",
      " 33  Delivery_Quarter                         4430 non-null   object        \n",
      " 34  Delivery_Year                            4430 non-null   int64         \n",
      " 35  TRF                                      4430 non-null   int64         \n",
      " 36  Total_Amount_Currency                    4430 non-null   object        \n",
      " 37  Total_Amount                             4430 non-null   int32         \n",
      " 38  Total_Taxable_Amount_Currency            4430 non-null   object        \n",
      " 39  Total_Taxable_Amount                     4430 non-null   int32         \n",
      " 40  Stage                                    4430 non-null   object        \n",
      " 41  Fecha                                    4430 non-null   datetime64[ns]\n",
      " 42  Opportunity_Duration                     4430 non-null   int32         \n",
      " 43  Total_Amount_USD                         3779 non-null   float64       \n",
      " 44  Total_Taxable_Amount_USD                 3779 non-null   float64       \n",
      " 45  Total_Amount_sobre_Total_Taxable_Amount  3779 non-null   float64       \n",
      " 46  Duracion_Familia                         4156 non-null   float64       \n",
      " 47  Duracion_Region                          4430 non-null   int64         \n",
      " 48  Duracion_Territory                       4416 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(9), int32(3), int64(15), object(21)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRODUCCION DE ARCHIVOS INTERMEDIOS\n",
    "entrenamiento.to_csv(\"entrenamiento-listo.csv\",index=False)\n",
    "test.to_csv(\"test-listo.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Total_Taxable_Amount'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['TRF'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
