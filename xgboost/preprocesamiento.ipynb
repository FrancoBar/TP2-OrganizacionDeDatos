{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "import category_encoders\n",
    "import math\n",
    "\n",
    "PREDICCION_REAL = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APERTURA DE ARCHIVO DE ARCHIVOS\n",
    "entrenamiento_temp = pd.read_csv(\"../Train_TP2_Datos_2020-2C.csv\")\n",
    "entrenamiento_temp = entrenamiento_temp[( entrenamiento_temp['Stage'] == 'Closed Won') | ( entrenamiento_temp['Stage'] == 'Closed Lost')]\n",
    "entrenamiento_temp = entrenamiento_temp.loc[(entrenamiento_temp[\"ASP_Currency\"] == entrenamiento_temp[\"Total_Taxable_Amount_Currency\"])]\n",
    "#entrenamiento = entrenamiento.loc[entrenamiento[\"Total_Taxable_Amount\"] > 0]\n",
    "\n",
    "test = pd.read_csv(\"../Test_TP2_Datos_2020-2C.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FORMATO FECHAS\n",
    "\n",
    "#Respalda fecha, usada para separa entrenamiento y test\n",
    "entrenamiento_temp['Fecha'] = pd.to_datetime(entrenamiento_temp['Opportunity_Created_Date'])\n",
    "columnas_fecha = ['Month','Last_Modified_Date','Account_Created_Date','Opportunity_Created_Date','Quote_Expiry_Date','Planned_Delivery_Start_Date','Planned_Delivery_End_Date']\n",
    "\n",
    "def formato_fechas(x):\n",
    "    for columna in columnas_fecha:\n",
    "        x[columna] = pd.to_datetime(x[columna])\n",
    "        \n",
    "formato_fechas(entrenamiento_temp)\n",
    "if(PREDICCION_REAL): \n",
    "    formato_fechas(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIVISION ENTRE SET DE ENTRENAMIENTO Y SET DE TEST\n",
    "\n",
    "if(PREDICCION_REAL):\n",
    "    entrenamiento = entrenamiento_temp.loc[entrenamiento_temp['Fecha'].dt.year <= 2017].copy()\n",
    "    validacion    = entrenamiento_temp.loc[(entrenamiento_temp['Fecha'].dt.year > 2017) & (entrenamiento_temp['Fecha'].dt.month < 6)].copy()\n",
    "else:\n",
    "    entrenamiento = entrenamiento_temp.loc[entrenamiento_temp['Fecha'].dt.year <= 2017].copy()\n",
    "    validacion    = entrenamiento_temp.loc[(entrenamiento_temp['Fecha'].dt.year > 2017) & (entrenamiento_temp['Fecha'].dt.month < 6)].copy()\n",
    "    test          = entrenamiento_temp.loc[(entrenamiento_temp['Fecha'].dt.year > 2017) & (entrenamiento_temp['Fecha'].dt.month >= 6)].copy()\n",
    "    entrenamiento_label = (entrenamiento['Stage'] == 'Closed Won').astype(int)\n",
    "    test_label          = (test['Stage'] == 'Closed Won').astype(int)\n",
    "\n",
    "del entrenamiento_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIMPIEZA\n",
    "\n",
    "entrenamiento = entrenamiento.drop(columns=['ASP_(converted)_Currency','Quote_Type','Brand','Product_Type','Size','Product_Category_B','Price','Currency','Last_Activity','Actual_Delivery_Date','Prod_Category_A'])\n",
    "test = test.drop(columns=['ASP_(converted)_Currency','Quote_Type','Brand','Product_Type','Size','Product_Category_B','Price','Currency','Last_Activity','Actual_Delivery_Date','Prod_Category_A'])\n",
    "validacion = validacion.drop(columns=['ASP_(converted)_Currency','Quote_Type','Brand','Product_Type','Size','Product_Category_B','Price','Currency','Last_Activity','Actual_Delivery_Date','Prod_Category_A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NUEVOS FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrego feature: Duracion de la oportunidad\n",
    "entrenamiento['Opportunity_Duration'] = (entrenamiento['Last_Modified_Date'] - entrenamiento['Opportunity_Created_Date']) / np.timedelta64(1, 'D')\n",
    "test['Opportunity_Duration'] = (test['Last_Modified_Date'] - test['Opportunity_Created_Date']) / np.timedelta64(1, 'D')\n",
    "validacion['Opportunity_Duration'] = (validacion['Last_Modified_Date'] - validacion['Opportunity_Created_Date']) / np.timedelta64(1, 'D')\n",
    "#Agrego feature: Total_Amount_USD\n",
    "entrenamiento[\"Total_Amount_USD\"] = entrenamiento[\"Total_Amount\"] * entrenamiento[\"ASP_(converted)\"] / entrenamiento[\"ASP\"]\n",
    "test[\"Total_Amount_USD\"] = test[\"Total_Amount\"] * test[\"ASP_(converted)\"] / test[\"ASP\"]\n",
    "validacion[\"Total_Amount_USD\"] = validacion[\"Total_Amount\"] * validacion[\"ASP_(converted)\"] / validacion[\"ASP\"]\n",
    "#Agrego feature: Total_Taxable_Amount_USD\n",
    "entrenamiento[\"Total_Taxable_Amount_USD\"] = entrenamiento[\"Total_Taxable_Amount\"] * entrenamiento[\"ASP_(converted)\"] / entrenamiento[\"ASP\"]\n",
    "test[\"Total_Taxable_Amount_USD\"] = test[\"Total_Taxable_Amount\"] * test[\"ASP_(converted)\"] / test[\"ASP\"]\n",
    "validacion[\"Total_Taxable_Amount_USD\"] = validacion[\"Total_Taxable_Amount\"] * validacion[\"ASP_(converted)\"] / validacion[\"ASP\"]\n",
    "#Agrego feature: Total_Amount_sobre_Total_Taxable_Amount\n",
    "entrenamiento[\"Total_Amount_sobre_Total_Taxable_Amount\"] = entrenamiento[\"Total_Amount_USD\"] / entrenamiento[\"Total_Taxable_Amount_USD\"]\n",
    "test[\"Total_Amount_sobre_Total_Taxable_Amount\"] = test[\"Total_Amount_USD\"] / test[\"Total_Taxable_Amount_USD\"]\n",
    "validacion[\"Total_Amount_sobre_Total_Taxable_Amount\"] = validacion[\"Total_Amount_USD\"] / validacion[\"Total_Taxable_Amount_USD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE - Duracion por familia\n",
    "df_zona = entrenamiento[['Stage','Region','Territory','Product_Family','Planned_Delivery_Start_Date']]\n",
    "df_zona = df_zona[df_zona['Stage'] == 'Closed Won']\n",
    "df_familia = df_zona.groupby(['Product_Family'])['Planned_Delivery_Start_Date'].agg(['max','min']).reset_index()\n",
    "df_familia['Duracion'] = (df_familia['max'] - df_familia['min']).dt.days\n",
    "df_familia.columns = ['Product_Family','Planed_Delivery_Fecha_Max','min','Duracion_Familia']\n",
    "entrenamiento = entrenamiento.merge(df_familia[['Product_Family','Duracion_Familia','Planed_Delivery_Fecha_Max']],on='Product_Family',how='left')\n",
    "entrenamiento['Vida_Util_Ventaja'] =  (entrenamiento['Planned_Delivery_Start_Date'] - entrenamiento['Planed_Delivery_Fecha_Max']).dt.days - entrenamiento['Duracion_Familia']\n",
    "entrenamiento = entrenamiento.drop('Planed_Delivery_Fecha_Max',1)\n",
    "test = test.merge(entrenamiento[['Product_Family','Duracion_Familia','Vida_Util_Ventaja']].drop_duplicates(subset=['Product_Family']),left_on='Product_Family',right_on='Product_Family',how='left')\n",
    "validacion = validacion.merge(entrenamiento[['Product_Family','Duracion_Familia','Vida_Util_Ventaja']].drop_duplicates(subset=['Product_Family']),left_on='Product_Family',right_on='Product_Family',how='left')\n",
    "\n",
    "#FEATURE - Duracion por region\n",
    "df_zona = entrenamiento[['Stage','Region','Territory','Product_Family','Planned_Delivery_Start_Date']]\n",
    "df_zona = df_zona[df_zona['Stage'] == 'Closed Won']\n",
    "df_region = df_zona.groupby(['Region'])['Planned_Delivery_Start_Date'].agg(['max','min']).reset_index()\n",
    "df_region['Duracion'] = (df_region['max'] - df_region['min']).dt.days\n",
    "df_region.columns = ['Region','Region_Planed_Delivery_Fecha_Max','Region_min','Duracion_Region']\n",
    "entrenamiento = entrenamiento.merge(df_region[['Region','Duracion_Region','Region_Planed_Delivery_Fecha_Max']],on='Region',how='left')\n",
    "entrenamiento['Region_Vida_Util_Ventaja'] =  (entrenamiento['Planned_Delivery_Start_Date'] - entrenamiento['Region_Planed_Delivery_Fecha_Max']).dt.days - entrenamiento['Duracion_Region']\n",
    "entrenamiento = entrenamiento.drop('Region_Planed_Delivery_Fecha_Max',1)\n",
    "test = test.merge(entrenamiento[['Region','Duracion_Region','Region_Vida_Util_Ventaja']].drop_duplicates(subset=['Region']),left_on='Region',right_on='Region',how='left')\n",
    "validacion = validacion.merge(entrenamiento[['Region','Duracion_Region','Region_Vida_Util_Ventaja']].drop_duplicates(subset=['Region']),left_on='Region',right_on='Region',how='left')\n",
    "\n",
    "#FEATURE - Duracion por territorio\n",
    "df_zona = entrenamiento[['Stage','Region','Territory','Product_Family','Planned_Delivery_Start_Date']]\n",
    "df_zona = df_zona[df_zona['Stage'] == 'Closed Won']\n",
    "df_territorio = df_zona.groupby(['Territory'])['Planned_Delivery_Start_Date'].agg(['max','min']).reset_index()\n",
    "df_territorio['Duracion'] = (df_territorio['max'] - df_territorio['min']).dt.days\n",
    "df_territorio.columns = ['Territory','Territory_Planed_Delivery_Fecha_Max','Territory_min','Duracion_Territory']\n",
    "entrenamiento = entrenamiento.merge(df_territorio[['Territory','Duracion_Territory','Territory_Planed_Delivery_Fecha_Max']],on='Territory',how='left')\n",
    "entrenamiento['Territory_Vida_Util_Ventaja'] =  (entrenamiento['Planned_Delivery_Start_Date'] - entrenamiento['Territory_Planed_Delivery_Fecha_Max']).dt.days - entrenamiento['Duracion_Territory']\n",
    "entrenamiento = entrenamiento.drop('Territory_Planed_Delivery_Fecha_Max',1)\n",
    "test = test.merge(entrenamiento[['Territory','Duracion_Territory','Territory_Vida_Util_Ventaja']].drop_duplicates(subset=['Territory']),left_on='Territory',right_on='Territory',how='left')\n",
    "validacion = validacion.merge(entrenamiento[['Territory','Duracion_Territory','Territory_Vida_Util_Ventaja']].drop_duplicates(subset=['Territory']),left_on='Territory',right_on='Territory',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FECHAS A DIAS\n",
    "def fecha_a_dias(x):\n",
    "    for columna in columnas_fecha:\n",
    "        x[columna] = x[columna].apply(lambda x : (x - pd.to_datetime('01/01/2000', format='%m/%d/%Y')).days)\n",
    "\n",
    "fecha_a_dias(entrenamiento)\n",
    "fecha_a_dias(test)\n",
    "fecha_a_dias(validacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef mean_encoding(train,test,col_group,col_mean,operacion):\\n    \\n    codificaciones = dict()\\n    nombre_col = col_group + \"_\" + col_mean + \"_\" + operacion\\n\\n    last_one = train.groupby(col_group).tail(1)\\n    for (idx, reg) in zip(last_one[col_group].index, last_one[col_group].values):\\n        codificaciones[reg] = (nombre_col, idx)\\n\\n    train[nombre_col] = train.groupby(col_group)[col_mean].transform(operacion)    \\n\\n    #Llenamos los NaN generados por cumsum con ceros.\\n    train.fillna(0,inplace = True)\\n\\n    #Guardamos la codificacion de cada categoria segun su nombre.\\n    for k, v in codificaciones.items():\\n        col = v[0]\\n        idx = v[1]\\n        codificaciones[k] = train.loc[idx, col]\\n    \\n    # Utilizo las ultimas codificaciones de cada categoria del train set para codificar el test set.\\n    # Para eso utilizo el diccionario de codificaciones.\\n\\n    #columnas_categoricas = x_test.select_dtypes(include=\\'category\\').columns\\n\\n    test[nombre_col] = test[col_group].astype(object)\\n    for (idx, reg) in zip(test[nombre_col].index, test[nombre_col]):\\n        if (reg in codificaciones):\\n            test.loc[idx, nombre_col] = codificaciones[reg]\\n        else:\\n            #Codifico como cero, se puede mejorar\\n            test.loc[idx, nombre_col] = 0\\n    test[nombre_col] = test[nombre_col].astype(float)\\n\\n    \\n\\ncolumnas_cat = [\"Region\",\"Territory\",\"Bureaucratic_Code\",\"Billing_Country\",\"Account_Type\",\"Opportunity_Type\",\"Delivery_Terms\",\"Last_Modified_By\",\"Product_Family\",\"Product_Name\",\"ASP_Currency\"]\\n\\ncolumnas_num = [\"Pricing, Delivery_Terms_Quote_Appr\",\"Pricing, Delivery_Terms_Approved\",\"Bureaucratic_Code_0_Approval\",\"Bureaucratic_Code_0_Approved\",\"Submitted_for_Approval\",\"ASP\",\"ASP_(converted)\",\"TRF\",\"Total_Amount_USD\",\"Total_Taxable_Amount_USD\",\"Opportunity_Duration\"]\\ni = 0\\nfor col_cat in columnas_cat:\\n    for col_num in columnas_num:\\n        print(i)\\n        i+= 1\\n        mean_encoding(entrenamiento.copy(),validacion,col_cat,col_num,\"mean\")\\n        mean_encoding(entrenamiento.copy(),validacion,col_cat,col_num,\"std\")\\n        mean_encoding(entrenamiento,test,col_cat,col_num,\"mean\")\\n        mean_encoding(entrenamiento,test,col_cat,col_num,\"std\")\\n        \\n\\ndef encoding_categorico(train,test,col_group,col_mean):\\n    \\n    codificaciones = dict()\\n\\n    last_one = train.groupby(col_group).tail(1)\\n    for (idx, reg) in zip(last_one[col_group].index, last_one[col_group].values):\\n        codificaciones[reg] = (col_group + \"_\" + col_mean, idx)\\n\\n    train[col_group + \"_\" + col_mean] = train.groupby(col_group)[col_mean].unique()    \\n\\n    #Llenamos los NaN generados por cumsum con ceros.\\n    train.fillna(0,inplace = True)\\n\\n    #Guardamos la codificacion de cada categoria segun su nombre.\\n    for k, v in codificaciones.items():\\n        col = v[0]\\n        idx = v[1]\\n        codificaciones[k] = train.loc[idx, col]\\n    \\n    # Utilizo las ultimas codificaciones de cada categoria del train set para codificar el test set.\\n    # Para eso utilizo el diccionario de codificaciones.\\n\\n    #columnas_categoricas = x_test.select_dtypes(include=\\'category\\').columns\\n\\n    test[col_group + \"_\" + col_mean] = test[col_group].astype(object)\\n    for (idx, reg) in zip(test[col_group + \"_\" + col_mean].index, test[col_group + \"_\" + col_mean]):\\n        if (reg in codificaciones):\\n            test.loc[idx, col_group + \"_\" + col_mean] = codificaciones[reg]\\n        else:\\n            #Codifico como cero, se puede mejorar\\n            test.loc[idx, col_group + \"_\" + col_mean] = 0\\n    test[col_group + \"_\" + col_mean] = test[col_group + \"_\" + col_mean].astype(float)\\n\\nfor col1,col2 in list(permutations(columnas_cat,2)):\\n    encoding_categorico(entrenamiento.copy(),validacion,col1,col2)\\n    encoding_categorico(entrenamiento,test,col1,col2)\\n    \\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Posibles nuevos features experimentales\"\"\"\n",
    "\"\"\"\n",
    "def mean_encoding(train,test,col_group,col_mean,operacion):\n",
    "    \n",
    "    codificaciones = dict()\n",
    "    nombre_col = col_group + \"_\" + col_mean + \"_\" + operacion\n",
    "\n",
    "    last_one = train.groupby(col_group).tail(1)\n",
    "    for (idx, reg) in zip(last_one[col_group].index, last_one[col_group].values):\n",
    "        codificaciones[reg] = (nombre_col, idx)\n",
    "\n",
    "    train[nombre_col] = train.groupby(col_group)[col_mean].transform(operacion)    \n",
    "\n",
    "    #Llenamos los NaN generados por cumsum con ceros.\n",
    "    train.fillna(0,inplace = True)\n",
    "\n",
    "    #Guardamos la codificacion de cada categoria segun su nombre.\n",
    "    for k, v in codificaciones.items():\n",
    "        col = v[0]\n",
    "        idx = v[1]\n",
    "        codificaciones[k] = train.loc[idx, col]\n",
    "    \n",
    "    # Utilizo las ultimas codificaciones de cada categoria del train set para codificar el test set.\n",
    "    # Para eso utilizo el diccionario de codificaciones.\n",
    "\n",
    "    #columnas_categoricas = x_test.select_dtypes(include='category').columns\n",
    "\n",
    "    test[nombre_col] = test[col_group].astype(object)\n",
    "    for (idx, reg) in zip(test[nombre_col].index, test[nombre_col]):\n",
    "        if (reg in codificaciones):\n",
    "            test.loc[idx, nombre_col] = codificaciones[reg]\n",
    "        else:\n",
    "            #Codifico como cero, se puede mejorar\n",
    "            test.loc[idx, nombre_col] = 0\n",
    "    test[nombre_col] = test[nombre_col].astype(float)\n",
    "\n",
    "    \n",
    "\n",
    "columnas_cat = [\"Region\",\"Territory\",\"Bureaucratic_Code\",\"Billing_Country\",\"Account_Type\",\"Opportunity_Type\",\"Delivery_Terms\",\"Last_Modified_By\",\"Product_Family\",\"Product_Name\",\"ASP_Currency\"]\n",
    "\n",
    "columnas_num = [\"Pricing, Delivery_Terms_Quote_Appr\",\"Pricing, Delivery_Terms_Approved\",\"Bureaucratic_Code_0_Approval\",\"Bureaucratic_Code_0_Approved\",\"Submitted_for_Approval\",\"ASP\",\"ASP_(converted)\",\"TRF\",\"Total_Amount_USD\",\"Total_Taxable_Amount_USD\",\"Opportunity_Duration\"]\n",
    "i = 0\n",
    "for col_cat in columnas_cat:\n",
    "    for col_num in columnas_num:\n",
    "        print(i)\n",
    "        i+= 1\n",
    "        mean_encoding(entrenamiento.copy(),validacion,col_cat,col_num,\"mean\")\n",
    "        mean_encoding(entrenamiento.copy(),validacion,col_cat,col_num,\"std\")\n",
    "        mean_encoding(entrenamiento,test,col_cat,col_num,\"mean\")\n",
    "        mean_encoding(entrenamiento,test,col_cat,col_num,\"std\")\n",
    "        \n",
    "\n",
    "def encoding_categorico(train,test,col_group,col_mean):\n",
    "    \n",
    "    codificaciones = dict()\n",
    "\n",
    "    last_one = train.groupby(col_group).tail(1)\n",
    "    for (idx, reg) in zip(last_one[col_group].index, last_one[col_group].values):\n",
    "        codificaciones[reg] = (col_group + \"_\" + col_mean, idx)\n",
    "\n",
    "    train[col_group + \"_\" + col_mean] = train.groupby(col_group)[col_mean].unique()    \n",
    "\n",
    "    #Llenamos los NaN generados por cumsum con ceros.\n",
    "    train.fillna(0,inplace = True)\n",
    "\n",
    "    #Guardamos la codificacion de cada categoria segun su nombre.\n",
    "    for k, v in codificaciones.items():\n",
    "        col = v[0]\n",
    "        idx = v[1]\n",
    "        codificaciones[k] = train.loc[idx, col]\n",
    "    \n",
    "    # Utilizo las ultimas codificaciones de cada categoria del train set para codificar el test set.\n",
    "    # Para eso utilizo el diccionario de codificaciones.\n",
    "\n",
    "    #columnas_categoricas = x_test.select_dtypes(include='category').columns\n",
    "\n",
    "    test[col_group + \"_\" + col_mean] = test[col_group].astype(object)\n",
    "    for (idx, reg) in zip(test[col_group + \"_\" + col_mean].index, test[col_group + \"_\" + col_mean]):\n",
    "        if (reg in codificaciones):\n",
    "            test.loc[idx, col_group + \"_\" + col_mean] = codificaciones[reg]\n",
    "        else:\n",
    "            #Codifico como cero, se puede mejorar\n",
    "            test.loc[idx, col_group + \"_\" + col_mean] = 0\n",
    "    test[col_group + \"_\" + col_mean] = test[col_group + \"_\" + col_mean].astype(float)\n",
    "\n",
    "for col1,col2 in list(permutations(columnas_cat,2)):\n",
    "    encoding_categorico(entrenamiento.copy(),validacion,col1,col2)\n",
    "    encoding_categorico(entrenamiento,test,col1,col2)\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef expansion_mean_encoding(columnas_categoricas,train,test,label):\\n    #Dividimos el dataset de entrenamiento en features y labels\\n    #Armo un df extra que me ayudara para codificar las categoricas.\\n    #x_y_train = filtrado.iloc[:-test_rows]\\n    #x_train = x_y_train.drop(\\'Stage\\', axis=1)\\n    #y_train = x_y_train[\\'Stage\\'].to_frame()\\n    #x_test = filtrado.iloc[-test_rows:].drop(\\'Stage\\', axis=1)\\n    #y_test = filtrado.iloc[-test_rows:][\\'Stage\\'].to_frame()\\n\\n    #En el set de train.\\n    #columnas_categoricas = x_train.select_dtypes(include=\\'category\\').columns\\n\\n    codificaciones = dict()\\n\\n    for col in columnas_categoricas:\\n        last_one = train.groupby(col).tail(1)\\n        for (idx, reg) in zip(last_one[col].index, last_one[col].values):\\n            codificaciones[reg] = (col, idx)\\n        cumulative_sum = train.groupby(col)[label].cumsum() - train[label]\\n        cumulative_count = train.groupby(col).cumcount()\\n        train[col] = cumulative_sum/cumulative_count\\n\\n    #Llenamos los NaN generados por cumsum con ceros.\\n    train.fillna(0,inplace = True)\\n\\n    #Guardamos la codificacion de cada categoria segun su nombre.\\n    for k, v in codificaciones.items():\\n        col = v[0]\\n        idx = v[1]\\n        codificaciones[k] = train.loc[idx, col]\\n    \\n    # Utilizo las ultimas codificaciones de cada categoria del train set para codificar el test set.\\n    # Para eso utilizo el diccionario de codificaciones.\\n\\n    #columnas_categoricas = x_test.select_dtypes(include=\\'category\\').columns\\n\\n    for col in columnas_categoricas:\\n        test[col] = test[col].astype(object)\\n        for (idx, reg) in zip(test[col].index, test[col]):\\n            if (reg in codificaciones):\\n                test.loc[idx, col] = codificaciones[reg]\\n            else:\\n                #Codifico como cero, se puede mejorar\\n                test.loc[idx, col] = 0\\n        test[col] = test[col].astype(float)\\n        \\ncolumnas_categoricas = list(entrenamiento.select_dtypes(include=[\\'object\\']).columns)\\nif \\'Stage\\' in columnas_categoricas : columnas_categoricas.remove(\\'Stage\\')\\nentrenamiento[\"label\"] = (entrenamiento[\\'Stage\\'] == \\'Closed Won\\').astype(int)\\nentrenamiento.sort_values(\"Fecha\")\\nexpansion_mean_encoding(columnas_categoricas,entrenamiento.copy().sort_values(\"Fecha\"),validacion,\"label\")\\nexpansion_mean_encoding(columnas_categoricas,entrenamiento,test,\"label\")\\nentrenamiento = entrenamiento.drop(columns=\\'label\\')\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#CATEGORICAS A NUMERICAS - PROMEDIO\"\"\"\n",
    "\"\"\"Se debe pasar train y test ordenados \"\"\"\n",
    "\"\"\"\n",
    "def expansion_mean_encoding(columnas_categoricas,train,test,label):\n",
    "    #Dividimos el dataset de entrenamiento en features y labels\n",
    "    #Armo un df extra que me ayudara para codificar las categoricas.\n",
    "    #x_y_train = filtrado.iloc[:-test_rows]\n",
    "    #x_train = x_y_train.drop('Stage', axis=1)\n",
    "    #y_train = x_y_train['Stage'].to_frame()\n",
    "    #x_test = filtrado.iloc[-test_rows:].drop('Stage', axis=1)\n",
    "    #y_test = filtrado.iloc[-test_rows:]['Stage'].to_frame()\n",
    "\n",
    "    #En el set de train.\n",
    "    #columnas_categoricas = x_train.select_dtypes(include='category').columns\n",
    "\n",
    "    codificaciones = dict()\n",
    "\n",
    "    for col in columnas_categoricas:\n",
    "        last_one = train.groupby(col).tail(1)\n",
    "        for (idx, reg) in zip(last_one[col].index, last_one[col].values):\n",
    "            codificaciones[reg] = (col, idx)\n",
    "        cumulative_sum = train.groupby(col)[label].cumsum() - train[label]\n",
    "        cumulative_count = train.groupby(col).cumcount()\n",
    "        train[col] = cumulative_sum/cumulative_count\n",
    "\n",
    "    #Llenamos los NaN generados por cumsum con ceros.\n",
    "    train.fillna(0,inplace = True)\n",
    "\n",
    "    #Guardamos la codificacion de cada categoria segun su nombre.\n",
    "    for k, v in codificaciones.items():\n",
    "        col = v[0]\n",
    "        idx = v[1]\n",
    "        codificaciones[k] = train.loc[idx, col]\n",
    "    \n",
    "    # Utilizo las ultimas codificaciones de cada categoria del train set para codificar el test set.\n",
    "    # Para eso utilizo el diccionario de codificaciones.\n",
    "\n",
    "    #columnas_categoricas = x_test.select_dtypes(include='category').columns\n",
    "\n",
    "    for col in columnas_categoricas:\n",
    "        test[col] = test[col].astype(object)\n",
    "        for (idx, reg) in zip(test[col].index, test[col]):\n",
    "            if (reg in codificaciones):\n",
    "                test.loc[idx, col] = codificaciones[reg]\n",
    "            else:\n",
    "                #Codifico como cero, se puede mejorar\n",
    "                test.loc[idx, col] = 0\n",
    "        test[col] = test[col].astype(float)\n",
    "        \n",
    "columnas_categoricas = list(entrenamiento.select_dtypes(include=['object']).columns)\n",
    "if 'Stage' in columnas_categoricas : columnas_categoricas.remove('Stage')\n",
    "entrenamiento[\"label\"] = (entrenamiento['Stage'] == 'Closed Won').astype(int)\n",
    "entrenamiento.sort_values(\"Fecha\")\n",
    "expansion_mean_encoding(columnas_categoricas,entrenamiento.copy().sort_values(\"Fecha\"),validacion,\"label\")\n",
    "expansion_mean_encoding(columnas_categoricas,entrenamiento,test,\"label\")\n",
    "entrenamiento = entrenamiento.drop(columns='label')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CATEGORICAS A NUMERICAS  - ORDINAL\n",
    "def categoricas_a_numericas(train,test,label,usar_label):\n",
    "    if (usar_label):\n",
    "        columnas_object = list(train.select_dtypes(include=['object']).columns)\n",
    "    else:\n",
    "        columnas_object = list(test.select_dtypes(include=['object']).columns)\n",
    "    if 'Stage' in columnas_object : columnas_object.remove('Stage')\n",
    "    ohe = category_encoders.cat_boost.CatBoostEncoder(cols = columnas_object,return_df = True)\n",
    "    ohe.fit(train,label)\n",
    "    if (usar_label):\n",
    "        columnas = ohe.transform(train,label)\n",
    "        for columna in columnas_object:\n",
    "            train[columna] = columnas[columna].copy()\n",
    "    else:\n",
    "        columnas = ohe.transform(test)\n",
    "        for columna in columnas_object:\n",
    "            test[columna] = columnas[columna].copy()\n",
    "categoricas_a_numericas(entrenamiento,test,entrenamiento_label,False)\n",
    "categoricas_a_numericas(entrenamiento,validacion,entrenamiento_label,False)\n",
    "categoricas_a_numericas(entrenamiento,test,entrenamiento_label,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Region', 'Territory', 'Bureaucratic_Code', 'Source ', 'Billing_Country', 'Account_Name', 'Opportunity_Name', 'Sales_Contract_No', 'Account_Owner', 'Opportunity_Owner', 'Account_Type', 'Opportunity_Type', 'Delivery_Terms', 'Quote_Expiry_Date', 'Last_Modified_By', 'Product_Family', 'Product_Name', 'ASP_Currency', 'ASP', 'ASP_(converted)', 'Planned_Delivery_End_Date', 'Delivery_Quarter', 'Total_Amount_Currency', 'Total_Amount', 'Total_Taxable_Amount_Currency', 'Total_Taxable_Amount', 'Opportunity_Duration', 'Total_Amount_USD', 'Total_Taxable_Amount_USD', 'Total_Amount_sobre_Total_Taxable_Amount', 'Duracion_Familia', 'Vida_Util_Ventaja', 'Duracion_Territory', 'Territory_Vida_Util_Ventaja']\n",
      "['Region', 'Territory', 'Bureaucratic_Code', 'Source ', 'Billing_Country', 'Account_Name', 'Opportunity_Name', 'Sales_Contract_No', 'Account_Owner', 'Opportunity_Owner', 'Account_Type', 'Opportunity_Type', 'Delivery_Terms', 'Quote_Expiry_Date', 'Last_Modified_By', 'Product_Family', 'Product_Name', 'ASP_Currency', 'ASP', 'ASP_(converted)', 'Planned_Delivery_End_Date', 'Delivery_Quarter', 'Total_Amount_Currency', 'Total_Amount', 'Total_Taxable_Amount_Currency', 'Total_Taxable_Amount', 'Opportunity_Duration', 'Total_Amount_USD', 'Total_Taxable_Amount_USD', 'Total_Amount_sobre_Total_Taxable_Amount', 'Duracion_Familia', 'Vida_Util_Ventaja', 'Duracion_Territory', 'Territory_Vida_Util_Ventaja']\n",
      "['Region', 'Territory', 'Bureaucratic_Code', 'Source ', 'Billing_Country', 'Account_Name', 'Opportunity_Name', 'Sales_Contract_No', 'Account_Owner', 'Opportunity_Owner', 'Account_Type', 'Opportunity_Type', 'Delivery_Terms', 'Quote_Expiry_Date', 'Last_Modified_By', 'Product_Family', 'Product_Name', 'ASP_Currency', 'ASP', 'ASP_(converted)', 'Planned_Delivery_End_Date', 'Delivery_Quarter', 'Total_Amount_Currency', 'Total_Amount', 'Total_Taxable_Amount_Currency', 'Total_Taxable_Amount', 'Opportunity_Duration', 'Total_Amount_USD', 'Total_Taxable_Amount_USD', 'Total_Amount_sobre_Total_Taxable_Amount', 'Duracion_Familia', 'Vida_Util_Ventaja', 'Duracion_Territory', 'Territory_Vida_Util_Ventaja']\n"
     ]
    }
   ],
   "source": [
    "def convertir_a_int(x):\n",
    "    columnas_float = list(x.select_dtypes(include=[np.float]).columns)\n",
    "    print(columnas_float)\n",
    "    for columna in columnas_float:\n",
    "        x.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "        copia = x[[columna]].copy().dropna(how=\"all\")\n",
    "        x[columna] = (copia[columna]*100).astype(int)\n",
    "\n",
    "entrenamiento = entrenamiento.loc[entrenamiento[\"Opportunity_Duration\"] != math.inf]\n",
    "test = test.loc[test[\"Opportunity_Duration\"] != math.inf]\n",
    "convertir_a_int(entrenamiento)\n",
    "convertir_a_int(test)\n",
    "convertir_a_int(validacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRODUCCION DE ARCHIVOS INTERMEDIOS\n",
    "entrenamiento.to_csv(\"entrenamiento-listo.csv\",index=False)\n",
    "test.to_csv(\"test-listo.csv\",index=False)\n",
    "validacion.to_csv(\"validacion-listo.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.0    965\n",
       "50.0    951\n",
       "59.0    906\n",
       "56.0    802\n",
       "53.0    710\n",
       "       ... \n",
       "5.0       4\n",
       "15.0      4\n",
       "7.0       3\n",
       "77.0      2\n",
       "74.0      1\n",
       "Name: Region, Length: 75, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entrenamiento[\"Region\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
