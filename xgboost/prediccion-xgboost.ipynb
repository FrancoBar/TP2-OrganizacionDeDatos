{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from datetime import datetime\n",
    "from itertools import combinations\n",
    "PREDICCION_REAL = True\n",
    "MAXIMIZAR_HIPERPARAMETROS = False\n",
    "PARAMETROS = {\"booster\":\"gbtree\", \"max_depth\":3, \"eta\": 0.1, \"objective\": \"binary:logistic\", \"nthread\":2,\"gamma\" : 0,\"subsample\" : 1}\n",
    "RONDAS = 500\n",
    "EARLY = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APERTURA DE ARCHIVO DE ARCHIVOS\n",
    "entrenamiento = pd.read_csv(\"entrenamiento-listo.csv\")\n",
    "validacion = pd.read_csv(\"validacion-listo.csv\")\n",
    "test = pd.read_csv(\"test-listo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILTRADO DE COLUMNAS - NO REMOVER STAGE O FECHA\n",
    "entrenamiento = entrenamiento.drop(columns=['ID','Opportunity_Name','Sales_Contract_No'])\n",
    "test = test.drop(columns=['ID','Opportunity_Name','Sales_Contract_No'])\n",
    "validacion = validacion.drop(columns=['ID','Opportunity_Name','Sales_Contract_No'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:45:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\teval-logloss:0.67829\ttrain-logloss:0.64753\n",
      "[1]\teval-logloss:0.66844\ttrain-logloss:0.61013\n",
      "[2]\teval-logloss:0.66442\ttrain-logloss:0.57852\n",
      "[3]\teval-logloss:0.64399\ttrain-logloss:0.54959\n",
      "[4]\teval-logloss:0.63515\ttrain-logloss:0.52738\n",
      "[5]\teval-logloss:0.63098\ttrain-logloss:0.50598\n",
      "[6]\teval-logloss:0.62022\ttrain-logloss:0.48836\n",
      "[7]\teval-logloss:0.62288\ttrain-logloss:0.47180\n",
      "[8]\teval-logloss:0.62354\ttrain-logloss:0.45806\n",
      "[9]\teval-logloss:0.63073\ttrain-logloss:0.44524\n",
      "[10]\teval-logloss:0.62842\ttrain-logloss:0.43317\n",
      "[11]\teval-logloss:0.61521\ttrain-logloss:0.42357\n",
      "[12]\teval-logloss:0.60735\ttrain-logloss:0.41375\n",
      "[13]\teval-logloss:0.60669\ttrain-logloss:0.40556\n",
      "[14]\teval-logloss:0.59679\ttrain-logloss:0.39831\n",
      "[15]\teval-logloss:0.60113\ttrain-logloss:0.39147\n",
      "[16]\teval-logloss:0.60815\ttrain-logloss:0.38565\n",
      "[17]\teval-logloss:0.60383\ttrain-logloss:0.37882\n",
      "[18]\teval-logloss:0.61067\ttrain-logloss:0.37333\n",
      "[19]\teval-logloss:0.61163\ttrain-logloss:0.36837\n",
      "[20]\teval-logloss:0.60556\ttrain-logloss:0.36340\n",
      "[21]\teval-logloss:0.59968\ttrain-logloss:0.35820\n",
      "[22]\teval-logloss:0.60382\ttrain-logloss:0.35357\n",
      "[23]\teval-logloss:0.60254\ttrain-logloss:0.35008\n",
      "[24]\teval-logloss:0.59835\ttrain-logloss:0.34642\n",
      "[25]\teval-logloss:0.60125\ttrain-logloss:0.34298\n",
      "[26]\teval-logloss:0.59891\ttrain-logloss:0.34011\n",
      "[27]\teval-logloss:0.60290\ttrain-logloss:0.33681\n",
      "[28]\teval-logloss:0.60008\ttrain-logloss:0.33416\n",
      "[29]\teval-logloss:0.59409\ttrain-logloss:0.33164\n",
      "[30]\teval-logloss:0.59057\ttrain-logloss:0.32830\n",
      "[31]\teval-logloss:0.59003\ttrain-logloss:0.32643\n",
      "[32]\teval-logloss:0.58782\ttrain-logloss:0.32448\n",
      "[33]\teval-logloss:0.59365\ttrain-logloss:0.32212\n",
      "[34]\teval-logloss:0.59423\ttrain-logloss:0.32039\n",
      "[35]\teval-logloss:0.58620\ttrain-logloss:0.31862\n",
      "[36]\teval-logloss:0.58638\ttrain-logloss:0.31707\n",
      "[37]\teval-logloss:0.58815\ttrain-logloss:0.31498\n",
      "[38]\teval-logloss:0.58612\ttrain-logloss:0.31330\n",
      "[39]\teval-logloss:0.58356\ttrain-logloss:0.31151\n",
      "[40]\teval-logloss:0.57935\ttrain-logloss:0.30978\n",
      "[41]\teval-logloss:0.57848\ttrain-logloss:0.30853\n",
      "[42]\teval-logloss:0.58080\ttrain-logloss:0.30717\n",
      "[43]\teval-logloss:0.57614\ttrain-logloss:0.30585\n",
      "[44]\teval-logloss:0.57820\ttrain-logloss:0.30485\n",
      "[45]\teval-logloss:0.58023\ttrain-logloss:0.30328\n",
      "[46]\teval-logloss:0.57901\ttrain-logloss:0.30184\n",
      "[47]\teval-logloss:0.57933\ttrain-logloss:0.30060\n",
      "[48]\teval-logloss:0.57368\ttrain-logloss:0.29950\n",
      "[49]\teval-logloss:0.57872\ttrain-logloss:0.29866\n",
      "[50]\teval-logloss:0.57813\ttrain-logloss:0.29776\n",
      "[51]\teval-logloss:0.57780\ttrain-logloss:0.29570\n",
      "[52]\teval-logloss:0.58058\ttrain-logloss:0.29511\n",
      "[53]\teval-logloss:0.57984\ttrain-logloss:0.29436\n",
      "[54]\teval-logloss:0.58135\ttrain-logloss:0.29376\n",
      "[55]\teval-logloss:0.58061\ttrain-logloss:0.29221\n",
      "[56]\teval-logloss:0.57966\ttrain-logloss:0.29033\n",
      "[57]\teval-logloss:0.57387\ttrain-logloss:0.28950\n",
      "[58]\teval-logloss:0.57414\ttrain-logloss:0.28888\n",
      "[59]\teval-logloss:0.57417\ttrain-logloss:0.28820\n",
      "[60]\teval-logloss:0.57945\ttrain-logloss:0.28752\n",
      "[61]\teval-logloss:0.57712\ttrain-logloss:0.28646\n",
      "[62]\teval-logloss:0.57855\ttrain-logloss:0.28582\n",
      "[63]\teval-logloss:0.57868\ttrain-logloss:0.28528\n",
      "[64]\teval-logloss:0.57571\ttrain-logloss:0.28477\n",
      "[65]\teval-logloss:0.57071\ttrain-logloss:0.28411\n",
      "[66]\teval-logloss:0.57042\ttrain-logloss:0.28364\n",
      "[67]\teval-logloss:0.57020\ttrain-logloss:0.28300\n",
      "[68]\teval-logloss:0.56824\ttrain-logloss:0.28250\n",
      "[69]\teval-logloss:0.57161\ttrain-logloss:0.28199\n",
      "[70]\teval-logloss:0.56954\ttrain-logloss:0.28152\n",
      "[71]\teval-logloss:0.57185\ttrain-logloss:0.28063\n",
      "[72]\teval-logloss:0.57213\ttrain-logloss:0.28030\n",
      "[73]\teval-logloss:0.57260\ttrain-logloss:0.27926\n",
      "[74]\teval-logloss:0.57443\ttrain-logloss:0.27862\n",
      "[75]\teval-logloss:0.57614\ttrain-logloss:0.27807\n",
      "[76]\teval-logloss:0.57575\ttrain-logloss:0.27759\n",
      "[77]\teval-logloss:0.57598\ttrain-logloss:0.27725\n",
      "[78]\teval-logloss:0.57547\ttrain-logloss:0.27626\n",
      "[79]\teval-logloss:0.57538\ttrain-logloss:0.27545\n",
      "[80]\teval-logloss:0.57581\ttrain-logloss:0.27482\n",
      "[81]\teval-logloss:0.57633\ttrain-logloss:0.27444\n",
      "[82]\teval-logloss:0.57408\ttrain-logloss:0.27316\n",
      "[83]\teval-logloss:0.57405\ttrain-logloss:0.27291\n",
      "[84]\teval-logloss:0.57426\ttrain-logloss:0.27244\n",
      "[85]\teval-logloss:0.57395\ttrain-logloss:0.27203\n",
      "[86]\teval-logloss:0.56867\ttrain-logloss:0.27099\n",
      "[87]\teval-logloss:0.57028\ttrain-logloss:0.27046\n",
      "[88]\teval-logloss:0.57030\ttrain-logloss:0.27011\n",
      "[89]\teval-logloss:0.56765\ttrain-logloss:0.26990\n",
      "[90]\teval-logloss:0.56751\ttrain-logloss:0.26950\n",
      "[91]\teval-logloss:0.56794\ttrain-logloss:0.26882\n",
      "[92]\teval-logloss:0.56460\ttrain-logloss:0.26779\n",
      "[93]\teval-logloss:0.56464\ttrain-logloss:0.26738\n",
      "[94]\teval-logloss:0.56792\ttrain-logloss:0.26687\n",
      "[95]\teval-logloss:0.56761\ttrain-logloss:0.26661\n",
      "[96]\teval-logloss:0.56787\ttrain-logloss:0.26621\n",
      "[97]\teval-logloss:0.56981\ttrain-logloss:0.26581\n",
      "[98]\teval-logloss:0.56927\ttrain-logloss:0.26542\n",
      "[99]\teval-logloss:0.56961\ttrain-logloss:0.26498\n",
      "[100]\teval-logloss:0.56966\ttrain-logloss:0.26471\n",
      "[101]\teval-logloss:0.56955\ttrain-logloss:0.26445\n",
      "[102]\teval-logloss:0.56817\ttrain-logloss:0.26397\n",
      "[103]\teval-logloss:0.56544\ttrain-logloss:0.26336\n",
      "[104]\teval-logloss:0.57003\ttrain-logloss:0.26312\n",
      "[105]\teval-logloss:0.57012\ttrain-logloss:0.26265\n",
      "[106]\teval-logloss:0.56954\ttrain-logloss:0.26220\n",
      "[107]\teval-logloss:0.57070\ttrain-logloss:0.26107\n",
      "[108]\teval-logloss:0.57058\ttrain-logloss:0.26053\n",
      "[109]\teval-logloss:0.56778\ttrain-logloss:0.25928\n",
      "[110]\teval-logloss:0.56530\ttrain-logloss:0.25887\n",
      "[111]\teval-logloss:0.56553\ttrain-logloss:0.25833\n",
      "[112]\teval-logloss:0.56588\ttrain-logloss:0.25803\n",
      "[113]\teval-logloss:0.56663\ttrain-logloss:0.25781\n",
      "[114]\teval-logloss:0.56626\ttrain-logloss:0.25744\n",
      "[115]\teval-logloss:0.56621\ttrain-logloss:0.25718\n",
      "[116]\teval-logloss:0.56458\ttrain-logloss:0.25648\n",
      "[117]\teval-logloss:0.56220\ttrain-logloss:0.25572\n",
      "[118]\teval-logloss:0.56221\ttrain-logloss:0.25461\n",
      "[119]\teval-logloss:0.56170\ttrain-logloss:0.25416\n",
      "[120]\teval-logloss:0.56212\ttrain-logloss:0.25301\n",
      "[121]\teval-logloss:0.56433\ttrain-logloss:0.25271\n",
      "[122]\teval-logloss:0.56508\ttrain-logloss:0.25211\n",
      "[123]\teval-logloss:0.56519\ttrain-logloss:0.25188\n",
      "[124]\teval-logloss:0.56573\ttrain-logloss:0.25167\n",
      "[125]\teval-logloss:0.56778\ttrain-logloss:0.25130\n",
      "[126]\teval-logloss:0.56541\ttrain-logloss:0.25109\n",
      "[127]\teval-logloss:0.56580\ttrain-logloss:0.25082\n",
      "[128]\teval-logloss:0.56727\ttrain-logloss:0.25037\n",
      "[129]\teval-logloss:0.56789\ttrain-logloss:0.24982\n",
      "[130]\teval-logloss:0.56781\ttrain-logloss:0.24911\n",
      "[131]\teval-logloss:0.56706\ttrain-logloss:0.24887\n",
      "[132]\teval-logloss:0.56694\ttrain-logloss:0.24857\n",
      "[133]\teval-logloss:0.56615\ttrain-logloss:0.24832\n",
      "[134]\teval-logloss:0.56683\ttrain-logloss:0.24812\n",
      "[135]\teval-logloss:0.56952\ttrain-logloss:0.24753\n",
      "[136]\teval-logloss:0.57020\ttrain-logloss:0.24706\n",
      "[137]\teval-logloss:0.57108\ttrain-logloss:0.24679\n",
      "[138]\teval-logloss:0.57042\ttrain-logloss:0.24625\n",
      "[139]\teval-logloss:0.57100\ttrain-logloss:0.24556\n",
      "[140]\teval-logloss:0.56892\ttrain-logloss:0.24535\n",
      "[141]\teval-logloss:0.56878\ttrain-logloss:0.24505\n",
      "[142]\teval-logloss:0.57134\ttrain-logloss:0.24475\n",
      "[143]\teval-logloss:0.57128\ttrain-logloss:0.24434\n",
      "[144]\teval-logloss:0.57122\ttrain-logloss:0.24423\n",
      "[145]\teval-logloss:0.57184\ttrain-logloss:0.24402\n",
      "[146]\teval-logloss:0.57094\ttrain-logloss:0.24368\n",
      "[147]\teval-logloss:0.57000\ttrain-logloss:0.24313\n",
      "[148]\teval-logloss:0.57183\ttrain-logloss:0.24244\n",
      "[149]\teval-logloss:0.57505\ttrain-logloss:0.24192\n",
      "[150]\teval-logloss:0.57467\ttrain-logloss:0.24149\n",
      "[151]\teval-logloss:0.57332\ttrain-logloss:0.24095\n",
      "[152]\teval-logloss:0.58077\ttrain-logloss:0.24071\n",
      "[153]\teval-logloss:0.57913\ttrain-logloss:0.24005\n",
      "[154]\teval-logloss:0.57999\ttrain-logloss:0.23963\n",
      "[155]\teval-logloss:0.57791\ttrain-logloss:0.23900\n",
      "[156]\teval-logloss:0.57788\ttrain-logloss:0.23842\n",
      "[157]\teval-logloss:0.57677\ttrain-logloss:0.23788\n",
      "[158]\teval-logloss:0.57805\ttrain-logloss:0.23766\n",
      "[159]\teval-logloss:0.57771\ttrain-logloss:0.23737\n",
      "[160]\teval-logloss:0.57790\ttrain-logloss:0.23675\n",
      "[161]\teval-logloss:0.57849\ttrain-logloss:0.23657\n",
      "[162]\teval-logloss:0.57857\ttrain-logloss:0.23643\n",
      "[163]\teval-logloss:0.57752\ttrain-logloss:0.23594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[164]\teval-logloss:0.57707\ttrain-logloss:0.23572\n",
      "[165]\teval-logloss:0.57623\ttrain-logloss:0.23549\n",
      "[166]\teval-logloss:0.57658\ttrain-logloss:0.23472\n",
      "[167]\teval-logloss:0.57684\ttrain-logloss:0.23443\n",
      "[168]\teval-logloss:0.57695\ttrain-logloss:0.23403\n",
      "[169]\teval-logloss:0.57629\ttrain-logloss:0.23356\n",
      "[170]\teval-logloss:0.57797\ttrain-logloss:0.23334\n",
      "[171]\teval-logloss:0.57777\ttrain-logloss:0.23298\n",
      "[172]\teval-logloss:0.57810\ttrain-logloss:0.23244\n",
      "[173]\teval-logloss:0.57583\ttrain-logloss:0.23190\n",
      "[174]\teval-logloss:0.57719\ttrain-logloss:0.23136\n",
      "[175]\teval-logloss:0.57682\ttrain-logloss:0.23053\n",
      "[176]\teval-logloss:0.57683\ttrain-logloss:0.22990\n",
      "[177]\teval-logloss:0.57465\ttrain-logloss:0.22927\n",
      "[178]\teval-logloss:0.57072\ttrain-logloss:0.22884\n",
      "[179]\teval-logloss:0.57241\ttrain-logloss:0.22848\n",
      "[180]\teval-logloss:0.56985\ttrain-logloss:0.22823\n",
      "[181]\teval-logloss:0.56986\ttrain-logloss:0.22800\n",
      "[182]\teval-logloss:0.56854\ttrain-logloss:0.22763\n",
      "[183]\teval-logloss:0.56702\ttrain-logloss:0.22715\n",
      "[184]\teval-logloss:0.56824\ttrain-logloss:0.22672\n",
      "[185]\teval-logloss:0.56961\ttrain-logloss:0.22642\n",
      "[186]\teval-logloss:0.57013\ttrain-logloss:0.22617\n",
      "[187]\teval-logloss:0.56975\ttrain-logloss:0.22562\n",
      "[188]\teval-logloss:0.56885\ttrain-logloss:0.22535\n",
      "[189]\teval-logloss:0.56628\ttrain-logloss:0.22513\n",
      "[190]\teval-logloss:0.56573\ttrain-logloss:0.22469\n",
      "[191]\teval-logloss:0.56568\ttrain-logloss:0.22456\n",
      "[192]\teval-logloss:0.56619\ttrain-logloss:0.22442\n",
      "[193]\teval-logloss:0.56722\ttrain-logloss:0.22393\n",
      "[194]\teval-logloss:0.56710\ttrain-logloss:0.22376\n",
      "[195]\teval-logloss:0.56770\ttrain-logloss:0.22334\n",
      "[196]\teval-logloss:0.56657\ttrain-logloss:0.22287\n",
      "[197]\teval-logloss:0.56575\ttrain-logloss:0.22243\n",
      "[198]\teval-logloss:0.56595\ttrain-logloss:0.22219\n",
      "[199]\teval-logloss:0.56529\ttrain-logloss:0.22173\n",
      "[200]\teval-logloss:0.56520\ttrain-logloss:0.22154\n",
      "[201]\teval-logloss:0.56582\ttrain-logloss:0.22097\n",
      "[202]\teval-logloss:0.56751\ttrain-logloss:0.22040\n",
      "[203]\teval-logloss:0.56786\ttrain-logloss:0.22017\n",
      "[204]\teval-logloss:0.56754\ttrain-logloss:0.21975\n",
      "[205]\teval-logloss:0.56918\ttrain-logloss:0.21950\n",
      "[206]\teval-logloss:0.57164\ttrain-logloss:0.21934\n",
      "[207]\teval-logloss:0.57440\ttrain-logloss:0.21923\n",
      "[208]\teval-logloss:0.57603\ttrain-logloss:0.21907\n",
      "[209]\teval-logloss:0.57206\ttrain-logloss:0.21890\n",
      "[210]\teval-logloss:0.57214\ttrain-logloss:0.21862\n",
      "[211]\teval-logloss:0.57188\ttrain-logloss:0.21824\n",
      "[212]\teval-logloss:0.57174\ttrain-logloss:0.21772\n",
      "[213]\teval-logloss:0.57236\ttrain-logloss:0.21735\n",
      "[214]\teval-logloss:0.56982\ttrain-logloss:0.21697\n",
      "[215]\teval-logloss:0.57058\ttrain-logloss:0.21679\n",
      "[216]\teval-logloss:0.57135\ttrain-logloss:0.21634\n",
      "[217]\teval-logloss:0.56942\ttrain-logloss:0.21617\n",
      "[218]\teval-logloss:0.56946\ttrain-logloss:0.21607\n",
      "[219]\teval-logloss:0.57067\ttrain-logloss:0.21585\n",
      "[220]\teval-logloss:0.57045\ttrain-logloss:0.21563\n",
      "[221]\teval-logloss:0.57010\ttrain-logloss:0.21530\n",
      "[222]\teval-logloss:0.57066\ttrain-logloss:0.21498\n",
      "[223]\teval-logloss:0.57014\ttrain-logloss:0.21462\n",
      "[224]\teval-logloss:0.56955\ttrain-logloss:0.21407\n",
      "[225]\teval-logloss:0.56929\ttrain-logloss:0.21394\n",
      "[226]\teval-logloss:0.56912\ttrain-logloss:0.21382\n",
      "[227]\teval-logloss:0.57003\ttrain-logloss:0.21348\n",
      "[228]\teval-logloss:0.56994\ttrain-logloss:0.21305\n",
      "[229]\teval-logloss:0.57052\ttrain-logloss:0.21263\n",
      "[230]\teval-logloss:0.57096\ttrain-logloss:0.21217\n",
      "[231]\teval-logloss:0.56772\ttrain-logloss:0.21203\n",
      "[232]\teval-logloss:0.56673\ttrain-logloss:0.21168\n",
      "[233]\teval-logloss:0.56610\ttrain-logloss:0.21124\n",
      "[234]\teval-logloss:0.56836\ttrain-logloss:0.21076\n",
      "[235]\teval-logloss:0.56835\ttrain-logloss:0.21041\n",
      "[236]\teval-logloss:0.56807\ttrain-logloss:0.21011\n",
      "[237]\teval-logloss:0.56803\ttrain-logloss:0.20968\n",
      "[238]\teval-logloss:0.56764\ttrain-logloss:0.20927\n",
      "[239]\teval-logloss:0.56753\ttrain-logloss:0.20896\n",
      "[240]\teval-logloss:0.56876\ttrain-logloss:0.20875\n",
      "[241]\teval-logloss:0.57645\ttrain-logloss:0.20844\n",
      "[242]\teval-logloss:0.57802\ttrain-logloss:0.20830\n",
      "[243]\teval-logloss:0.57814\ttrain-logloss:0.20784\n",
      "[244]\teval-logloss:0.57721\ttrain-logloss:0.20754\n",
      "[245]\teval-logloss:0.57577\ttrain-logloss:0.20710\n",
      "[246]\teval-logloss:0.57772\ttrain-logloss:0.20657\n",
      "[247]\teval-logloss:0.58005\ttrain-logloss:0.20625\n",
      "[248]\teval-logloss:0.57980\ttrain-logloss:0.20591\n",
      "[249]\teval-logloss:0.58040\ttrain-logloss:0.20548\n",
      "[250]\teval-logloss:0.58293\ttrain-logloss:0.20535\n",
      "[251]\teval-logloss:0.58005\ttrain-logloss:0.20523\n",
      "[252]\teval-logloss:0.57904\ttrain-logloss:0.20502\n",
      "[253]\teval-logloss:0.58053\ttrain-logloss:0.20461\n",
      "[254]\teval-logloss:0.58195\ttrain-logloss:0.20452\n",
      "[255]\teval-logloss:0.58213\ttrain-logloss:0.20441\n",
      "[256]\teval-logloss:0.58158\ttrain-logloss:0.20411\n",
      "[257]\teval-logloss:0.57952\ttrain-logloss:0.20398\n",
      "[258]\teval-logloss:0.57859\ttrain-logloss:0.20363\n",
      "[259]\teval-logloss:0.57861\ttrain-logloss:0.20332\n",
      "[260]\teval-logloss:0.57820\ttrain-logloss:0.20301\n",
      "[261]\teval-logloss:0.57510\ttrain-logloss:0.20257\n",
      "[262]\teval-logloss:0.57250\ttrain-logloss:0.20236\n",
      "[263]\teval-logloss:0.57639\ttrain-logloss:0.20192\n",
      "[264]\teval-logloss:0.57661\ttrain-logloss:0.20163\n",
      "[265]\teval-logloss:0.57758\ttrain-logloss:0.20152\n",
      "[266]\teval-logloss:0.57860\ttrain-logloss:0.20135\n",
      "[267]\teval-logloss:0.57851\ttrain-logloss:0.20116\n",
      "[268]\teval-logloss:0.57754\ttrain-logloss:0.20107\n",
      "[269]\teval-logloss:0.57721\ttrain-logloss:0.20093\n",
      "[270]\teval-logloss:0.57735\ttrain-logloss:0.20066\n",
      "[271]\teval-logloss:0.57778\ttrain-logloss:0.20053\n",
      "[272]\teval-logloss:0.57794\ttrain-logloss:0.20002\n",
      "[273]\teval-logloss:0.57645\ttrain-logloss:0.19966\n",
      "[274]\teval-logloss:0.57579\ttrain-logloss:0.19940\n",
      "[275]\teval-logloss:0.57536\ttrain-logloss:0.19911\n",
      "[276]\teval-logloss:0.57860\ttrain-logloss:0.19885\n",
      "[277]\teval-logloss:0.58159\ttrain-logloss:0.19853\n",
      "[278]\teval-logloss:0.58068\ttrain-logloss:0.19817\n",
      "[279]\teval-logloss:0.58491\ttrain-logloss:0.19801\n",
      "[280]\teval-logloss:0.58488\ttrain-logloss:0.19757\n",
      "[281]\teval-logloss:0.58365\ttrain-logloss:0.19735\n",
      "[282]\teval-logloss:0.58384\ttrain-logloss:0.19717\n",
      "[283]\teval-logloss:0.58134\ttrain-logloss:0.19694\n",
      "[284]\teval-logloss:0.58148\ttrain-logloss:0.19660\n",
      "[285]\teval-logloss:0.58147\ttrain-logloss:0.19643\n",
      "[286]\teval-logloss:0.58157\ttrain-logloss:0.19610\n",
      "[287]\teval-logloss:0.58175\ttrain-logloss:0.19602\n",
      "[288]\teval-logloss:0.58207\ttrain-logloss:0.19578\n",
      "[289]\teval-logloss:0.57105\ttrain-logloss:0.19543\n",
      "[290]\teval-logloss:0.57416\ttrain-logloss:0.19534\n",
      "[291]\teval-logloss:0.57568\ttrain-logloss:0.19501\n",
      "[292]\teval-logloss:0.58000\ttrain-logloss:0.19469\n",
      "[293]\teval-logloss:0.57801\ttrain-logloss:0.19429\n",
      "[294]\teval-logloss:0.57713\ttrain-logloss:0.19398\n",
      "[295]\teval-logloss:0.57746\ttrain-logloss:0.19357\n",
      "[296]\teval-logloss:0.57827\ttrain-logloss:0.19332\n",
      "[297]\teval-logloss:0.58033\ttrain-logloss:0.19306\n",
      "[298]\teval-logloss:0.58115\ttrain-logloss:0.19275\n",
      "[299]\teval-logloss:0.58112\ttrain-logloss:0.19257\n",
      "[300]\teval-logloss:0.58067\ttrain-logloss:0.19217\n",
      "[301]\teval-logloss:0.58107\ttrain-logloss:0.19187\n",
      "[302]\teval-logloss:0.58133\ttrain-logloss:0.19181\n",
      "[303]\teval-logloss:0.58317\ttrain-logloss:0.19169\n",
      "[304]\teval-logloss:0.58667\ttrain-logloss:0.19162\n",
      "[305]\teval-logloss:0.58562\ttrain-logloss:0.19152\n",
      "[306]\teval-logloss:0.58417\ttrain-logloss:0.19124\n",
      "[307]\teval-logloss:0.58578\ttrain-logloss:0.19096\n",
      "[308]\teval-logloss:0.58543\ttrain-logloss:0.19062\n",
      "[309]\teval-logloss:0.58379\ttrain-logloss:0.19027\n",
      "[310]\teval-logloss:0.58439\ttrain-logloss:0.18998\n",
      "[311]\teval-logloss:0.58406\ttrain-logloss:0.18970\n",
      "[312]\teval-logloss:0.58443\ttrain-logloss:0.18936\n",
      "[313]\teval-logloss:0.58437\ttrain-logloss:0.18913\n",
      "[314]\teval-logloss:0.58537\ttrain-logloss:0.18887\n",
      "[315]\teval-logloss:0.58836\ttrain-logloss:0.18863\n",
      "[316]\teval-logloss:0.58823\ttrain-logloss:0.18857\n",
      "[317]\teval-logloss:0.59152\ttrain-logloss:0.18820\n",
      "[318]\teval-logloss:0.58962\ttrain-logloss:0.18779\n",
      "[319]\teval-logloss:0.58959\ttrain-logloss:0.18763\n",
      "[320]\teval-logloss:0.58768\ttrain-logloss:0.18716\n",
      "[321]\teval-logloss:0.58771\ttrain-logloss:0.18709\n",
      "[322]\teval-logloss:0.58783\ttrain-logloss:0.18675\n",
      "[323]\teval-logloss:0.58780\ttrain-logloss:0.18661\n",
      "[324]\teval-logloss:0.59584\ttrain-logloss:0.18647\n",
      "[325]\teval-logloss:0.59800\ttrain-logloss:0.18623\n",
      "[326]\teval-logloss:0.59717\ttrain-logloss:0.18615\n",
      "[327]\teval-logloss:0.59560\ttrain-logloss:0.18583\n",
      "[328]\teval-logloss:0.59801\ttrain-logloss:0.18576\n",
      "[329]\teval-logloss:0.59526\ttrain-logloss:0.18566\n",
      "[330]\teval-logloss:0.59524\ttrain-logloss:0.18554\n",
      "[331]\teval-logloss:0.59535\ttrain-logloss:0.18542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[332]\teval-logloss:0.59436\ttrain-logloss:0.18503\n",
      "[333]\teval-logloss:0.59413\ttrain-logloss:0.18477\n",
      "[334]\teval-logloss:0.59639\ttrain-logloss:0.18446\n",
      "[335]\teval-logloss:0.59644\ttrain-logloss:0.18422\n",
      "[336]\teval-logloss:0.59681\ttrain-logloss:0.18397\n",
      "[337]\teval-logloss:0.59635\ttrain-logloss:0.18387\n",
      "[338]\teval-logloss:0.59691\ttrain-logloss:0.18372\n",
      "[339]\teval-logloss:0.59704\ttrain-logloss:0.18351\n",
      "[340]\teval-logloss:0.59496\ttrain-logloss:0.18326\n",
      "[341]\teval-logloss:0.59321\ttrain-logloss:0.18317\n",
      "[342]\teval-logloss:0.59323\ttrain-logloss:0.18304\n",
      "[343]\teval-logloss:0.59306\ttrain-logloss:0.18290\n",
      "[344]\teval-logloss:0.59279\ttrain-logloss:0.18254\n",
      "[345]\teval-logloss:0.59219\ttrain-logloss:0.18225\n",
      "[346]\teval-logloss:0.59154\ttrain-logloss:0.18200\n",
      "[347]\teval-logloss:0.59531\ttrain-logloss:0.18180\n",
      "[348]\teval-logloss:0.59545\ttrain-logloss:0.18162\n",
      "[349]\teval-logloss:0.59542\ttrain-logloss:0.18147\n",
      "[350]\teval-logloss:0.59869\ttrain-logloss:0.18118\n",
      "[351]\teval-logloss:0.59869\ttrain-logloss:0.18098\n",
      "[352]\teval-logloss:0.59904\ttrain-logloss:0.18091\n",
      "[353]\teval-logloss:0.59938\ttrain-logloss:0.18069\n",
      "[354]\teval-logloss:0.59419\ttrain-logloss:0.18040\n",
      "[355]\teval-logloss:0.59778\ttrain-logloss:0.18021\n",
      "[356]\teval-logloss:0.59755\ttrain-logloss:0.18000\n",
      "[357]\teval-logloss:0.59753\ttrain-logloss:0.17982\n",
      "[358]\teval-logloss:0.59979\ttrain-logloss:0.17976\n",
      "[359]\teval-logloss:0.60066\ttrain-logloss:0.17961\n",
      "[360]\teval-logloss:0.60125\ttrain-logloss:0.17948\n",
      "[361]\teval-logloss:0.60380\ttrain-logloss:0.17916\n",
      "[362]\teval-logloss:0.60442\ttrain-logloss:0.17894\n",
      "[363]\teval-logloss:0.60732\ttrain-logloss:0.17882\n",
      "[364]\teval-logloss:0.60631\ttrain-logloss:0.17873\n",
      "[365]\teval-logloss:0.60593\ttrain-logloss:0.17844\n",
      "[366]\teval-logloss:0.60943\ttrain-logloss:0.17827\n",
      "[367]\teval-logloss:0.61223\ttrain-logloss:0.17800\n",
      "[368]\teval-logloss:0.61286\ttrain-logloss:0.17776\n",
      "[369]\teval-logloss:0.61286\ttrain-logloss:0.17755\n",
      "[370]\teval-logloss:0.61072\ttrain-logloss:0.17747\n",
      "[371]\teval-logloss:0.61048\ttrain-logloss:0.17738\n",
      "[372]\teval-logloss:0.61131\ttrain-logloss:0.17722\n",
      "[373]\teval-logloss:0.61138\ttrain-logloss:0.17706\n",
      "[374]\teval-logloss:0.61059\ttrain-logloss:0.17695\n",
      "[375]\teval-logloss:0.60956\ttrain-logloss:0.17679\n",
      "[376]\teval-logloss:0.60876\ttrain-logloss:0.17654\n",
      "[377]\teval-logloss:0.60850\ttrain-logloss:0.17643\n",
      "[378]\teval-logloss:0.60865\ttrain-logloss:0.17632\n",
      "[379]\teval-logloss:0.60864\ttrain-logloss:0.17613\n",
      "[380]\teval-logloss:0.60914\ttrain-logloss:0.17586\n",
      "[381]\teval-logloss:0.61247\ttrain-logloss:0.17566\n",
      "[382]\teval-logloss:0.61268\ttrain-logloss:0.17537\n",
      "[383]\teval-logloss:0.61083\ttrain-logloss:0.17528\n",
      "[384]\teval-logloss:0.60958\ttrain-logloss:0.17500\n",
      "[385]\teval-logloss:0.61113\ttrain-logloss:0.17477\n",
      "[386]\teval-logloss:0.61049\ttrain-logloss:0.17460\n",
      "[387]\teval-logloss:0.61047\ttrain-logloss:0.17448\n",
      "[388]\teval-logloss:0.60640\ttrain-logloss:0.17440\n",
      "[389]\teval-logloss:0.60582\ttrain-logloss:0.17410\n",
      "[390]\teval-logloss:0.60574\ttrain-logloss:0.17390\n",
      "[391]\teval-logloss:0.60648\ttrain-logloss:0.17378\n",
      "[392]\teval-logloss:0.60706\ttrain-logloss:0.17361\n",
      "[393]\teval-logloss:0.60789\ttrain-logloss:0.17348\n",
      "[394]\teval-logloss:0.60712\ttrain-logloss:0.17335\n",
      "[395]\teval-logloss:0.60766\ttrain-logloss:0.17325\n",
      "[396]\teval-logloss:0.60822\ttrain-logloss:0.17291\n",
      "[397]\teval-logloss:0.60826\ttrain-logloss:0.17262\n",
      "[398]\teval-logloss:0.60838\ttrain-logloss:0.17247\n",
      "[399]\teval-logloss:0.60895\ttrain-logloss:0.17223\n",
      "[400]\teval-logloss:0.60946\ttrain-logloss:0.17200\n",
      "[401]\teval-logloss:0.61126\ttrain-logloss:0.17170\n",
      "[402]\teval-logloss:0.61308\ttrain-logloss:0.17165\n",
      "[403]\teval-logloss:0.61355\ttrain-logloss:0.17142\n",
      "[404]\teval-logloss:0.61439\ttrain-logloss:0.17117\n",
      "[405]\teval-logloss:0.61567\ttrain-logloss:0.17102\n",
      "[406]\teval-logloss:0.61588\ttrain-logloss:0.17080\n",
      "[407]\teval-logloss:0.61576\ttrain-logloss:0.17056\n",
      "[408]\teval-logloss:0.61563\ttrain-logloss:0.17050\n",
      "[409]\teval-logloss:0.61144\ttrain-logloss:0.17042\n",
      "[410]\teval-logloss:0.61171\ttrain-logloss:0.17030\n",
      "[411]\teval-logloss:0.61661\ttrain-logloss:0.17013\n",
      "[412]\teval-logloss:0.61666\ttrain-logloss:0.17006\n",
      "[413]\teval-logloss:0.61798\ttrain-logloss:0.16993\n",
      "[414]\teval-logloss:0.61738\ttrain-logloss:0.16969\n",
      "[415]\teval-logloss:0.61741\ttrain-logloss:0.16963\n",
      "[416]\teval-logloss:0.61746\ttrain-logloss:0.16960\n",
      "[417]\teval-logloss:0.61684\ttrain-logloss:0.16940\n",
      "[418]\teval-logloss:0.61284\ttrain-logloss:0.16913\n",
      "[419]\teval-logloss:0.61064\ttrain-logloss:0.16892\n",
      "[420]\teval-logloss:0.61059\ttrain-logloss:0.16879\n",
      "[421]\teval-logloss:0.61213\ttrain-logloss:0.16853\n",
      "[422]\teval-logloss:0.61211\ttrain-logloss:0.16828\n",
      "[423]\teval-logloss:0.61289\ttrain-logloss:0.16814\n",
      "[424]\teval-logloss:0.61363\ttrain-logloss:0.16796\n",
      "[425]\teval-logloss:0.61403\ttrain-logloss:0.16775\n",
      "[426]\teval-logloss:0.61326\ttrain-logloss:0.16753\n",
      "[427]\teval-logloss:0.61310\ttrain-logloss:0.16726\n",
      "[428]\teval-logloss:0.61307\ttrain-logloss:0.16697\n",
      "[429]\teval-logloss:0.61165\ttrain-logloss:0.16684\n",
      "[430]\teval-logloss:0.61042\ttrain-logloss:0.16661\n",
      "[431]\teval-logloss:0.61001\ttrain-logloss:0.16625\n",
      "[432]\teval-logloss:0.61002\ttrain-logloss:0.16608\n",
      "[433]\teval-logloss:0.61063\ttrain-logloss:0.16590\n",
      "[434]\teval-logloss:0.61145\ttrain-logloss:0.16566\n",
      "[435]\teval-logloss:0.61317\ttrain-logloss:0.16542\n",
      "[436]\teval-logloss:0.61239\ttrain-logloss:0.16532\n",
      "[437]\teval-logloss:0.61247\ttrain-logloss:0.16505\n",
      "[438]\teval-logloss:0.61273\ttrain-logloss:0.16491\n",
      "[439]\teval-logloss:0.61232\ttrain-logloss:0.16470\n",
      "[440]\teval-logloss:0.61234\ttrain-logloss:0.16465\n",
      "[441]\teval-logloss:0.61230\ttrain-logloss:0.16453\n",
      "[442]\teval-logloss:0.61337\ttrain-logloss:0.16442\n",
      "[443]\teval-logloss:0.61314\ttrain-logloss:0.16434\n",
      "[444]\teval-logloss:0.61461\ttrain-logloss:0.16425\n",
      "[445]\teval-logloss:0.61489\ttrain-logloss:0.16411\n",
      "[446]\teval-logloss:0.61406\ttrain-logloss:0.16394\n",
      "[447]\teval-logloss:0.61414\ttrain-logloss:0.16382\n",
      "[448]\teval-logloss:0.61415\ttrain-logloss:0.16375\n",
      "[449]\teval-logloss:0.61548\ttrain-logloss:0.16365\n",
      "[450]\teval-logloss:0.61479\ttrain-logloss:0.16333\n",
      "[451]\teval-logloss:0.61548\ttrain-logloss:0.16311\n",
      "[452]\teval-logloss:0.61555\ttrain-logloss:0.16294\n",
      "[453]\teval-logloss:0.61665\ttrain-logloss:0.16276\n",
      "[454]\teval-logloss:0.61664\ttrain-logloss:0.16264\n",
      "[455]\teval-logloss:0.61704\ttrain-logloss:0.16250\n",
      "[456]\teval-logloss:0.61685\ttrain-logloss:0.16235\n",
      "[457]\teval-logloss:0.61744\ttrain-logloss:0.16220\n",
      "[458]\teval-logloss:0.61740\ttrain-logloss:0.16216\n",
      "[459]\teval-logloss:0.61789\ttrain-logloss:0.16193\n",
      "[460]\teval-logloss:0.61925\ttrain-logloss:0.16168\n",
      "[461]\teval-logloss:0.61498\ttrain-logloss:0.16149\n",
      "[462]\teval-logloss:0.61501\ttrain-logloss:0.16135\n",
      "[463]\teval-logloss:0.61510\ttrain-logloss:0.16125\n",
      "[464]\teval-logloss:0.61481\ttrain-logloss:0.16106\n",
      "[465]\teval-logloss:0.61477\ttrain-logloss:0.16093\n",
      "[466]\teval-logloss:0.61597\ttrain-logloss:0.16084\n",
      "[467]\teval-logloss:0.61643\ttrain-logloss:0.16065\n",
      "[468]\teval-logloss:0.62280\ttrain-logloss:0.16034\n",
      "[469]\teval-logloss:0.62273\ttrain-logloss:0.16023\n",
      "[470]\teval-logloss:0.62272\ttrain-logloss:0.16013\n",
      "[471]\teval-logloss:0.62279\ttrain-logloss:0.16005\n",
      "[472]\teval-logloss:0.62834\ttrain-logloss:0.15990\n",
      "[473]\teval-logloss:0.62857\ttrain-logloss:0.15981\n",
      "[474]\teval-logloss:0.62766\ttrain-logloss:0.15973\n",
      "[475]\teval-logloss:0.62734\ttrain-logloss:0.15950\n",
      "[476]\teval-logloss:0.62540\ttrain-logloss:0.15914\n",
      "[477]\teval-logloss:0.62603\ttrain-logloss:0.15900\n",
      "[478]\teval-logloss:0.62690\ttrain-logloss:0.15887\n",
      "[479]\teval-logloss:0.62665\ttrain-logloss:0.15871\n",
      "[480]\teval-logloss:0.62662\ttrain-logloss:0.15862\n",
      "[481]\teval-logloss:0.62675\ttrain-logloss:0.15854\n",
      "[482]\teval-logloss:0.62680\ttrain-logloss:0.15842\n",
      "[483]\teval-logloss:0.62605\ttrain-logloss:0.15830\n",
      "[484]\teval-logloss:0.62603\ttrain-logloss:0.15819\n",
      "[485]\teval-logloss:0.62604\ttrain-logloss:0.15814\n",
      "[486]\teval-logloss:0.62603\ttrain-logloss:0.15806\n",
      "[487]\teval-logloss:0.62646\ttrain-logloss:0.15773\n",
      "[488]\teval-logloss:0.62671\ttrain-logloss:0.15753\n",
      "[489]\teval-logloss:0.62682\ttrain-logloss:0.15727\n",
      "[490]\teval-logloss:0.62560\ttrain-logloss:0.15703\n",
      "[491]\teval-logloss:0.62742\ttrain-logloss:0.15681\n",
      "[492]\teval-logloss:0.62747\ttrain-logloss:0.15665\n",
      "[493]\teval-logloss:0.62775\ttrain-logloss:0.15647\n",
      "[494]\teval-logloss:0.62720\ttrain-logloss:0.15640\n",
      "[495]\teval-logloss:0.62739\ttrain-logloss:0.15626\n",
      "[496]\teval-logloss:0.62736\ttrain-logloss:0.15617\n",
      "[497]\teval-logloss:0.62734\ttrain-logloss:0.15592\n",
      "[498]\teval-logloss:0.62786\ttrain-logloss:0.15581\n",
      "[499]\teval-logloss:0.62806\ttrain-logloss:0.15568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2551\n"
     ]
    }
   ],
   "source": [
    "if(PREDICCION_REAL):\n",
    "    objetivo = (entrenamiento['Stage'] == 'Closed Won').astype(int)\n",
    "    objetivo_val = (validacion['Stage'] == 'Closed Won').astype(int)\n",
    "    entrenamiento = entrenamiento.drop(columns=['Stage','Fecha'])\n",
    "    validacion = validacion.drop(columns=['Stage','Fecha'])\n",
    "    \n",
    "    d_entrenamiento = xgb.DMatrix(entrenamiento.values, objetivo.values)\n",
    "    d_prueba = xgb.DMatrix(test.values)\n",
    "    d_validacion = xgb.DMatrix(validacion.values, objetivo_val.values)\n",
    "    \n",
    "    evaluacion = [(d_validacion, 'eval'), (d_entrenamiento, 'train')]\n",
    "    \n",
    "    bst = xgb.train(PARAMETROS, d_entrenamiento, RONDAS,evaluacion,early_stopping_rounds = EARLY)\n",
    "    preds = bst.predict(d_prueba)\n",
    "\n",
    "    resultados = test[['Opportunity_ID']].copy()\n",
    "    resultados['Target'] = pd.Series(preds)\n",
    "    #resultados = resultados.groupby('Opportunity_ID').mean()\n",
    "    #resultados = resultados.reset_index()\n",
    "    #resultados['Target'] = resultados['Target'].apply(lambda x: int(x >= 0.5))\n",
    "    \n",
    "    resultados.to_csv(\"prediccion.csv\", index=False)\n",
    "    print(resultados['Target'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gianb\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3351: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if(PREDICCION_REAL): sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenamiento_label = (entrenamiento['Stage'] == 'Closed Won').astype(int)\n",
    "validacion_label    = (validacion['Stage'] == 'Closed Won').astype(int)\n",
    "test_label          = (test['Stage'] == 'Closed Won').astype(int)\n",
    "\n",
    "set_entrenamiento = xgb.DMatrix(entrenamiento.drop(columns=['Stage','Fecha']),label = entrenamiento_label)\n",
    "set_validacion = xgb.DMatrix(validacion.drop(columns=['Stage','Fecha']),label = validacion_label)\n",
    "set_test  = xgb.DMatrix(test .drop(columns=['Stage','Fecha']),label = test_label)\n",
    "evaluacion = [(set_validacion, 'eval'), (set_entrenamiento, 'train')]\n",
    "\n",
    "modelo = xgb.train(PARAMETROS, set_entrenamiento, RONDAS, evaluacion, early_stopping_rounds=EARLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion = modelo.predict(set_test)\n",
    "\n",
    "resultados = test[['Opportunity_ID']].copy()\n",
    "resultados['Target'] = pd.Series(prediccion)\n",
    "#resultados = resultados.groupby('Opportunity_ID').mean()\n",
    "#resultados = resultados.reset_index()\n",
    "#resultados['Target'] = resultados['Target'].apply(lambda x: int(x >= 0.5))\n",
    "\n",
    "resultados.to_csv(\"prediccion.csv\", index=False)\n",
    "print(resultados['Target'].count())\n",
    "\n",
    "prediccion = [1 if i > .5 else 0 for i in prediccion]\n",
    "\n",
    "def metricas(objetivo, prediccion):\n",
    "    matriz_conf = confusion_matrix(objetivo, prediccion)\n",
    "    score = accuracy_score(objetivo, prediccion)\n",
    "    reporte = classification_report(objetivo, prediccion)\n",
    "    metricas = [matriz_conf, score, reporte]\n",
    "    return(metricas)\n",
    "\n",
    "metrics = metricas(test_label, prediccion)\n",
    "print(\"Prediccion Test\")\n",
    "[print(i) for i in metrics]\n",
    "print(skl.metrics.log_loss(test_label,prediccion))\n",
    "\n",
    "prediccion = modelo.predict(set_validacion)\n",
    "prediccion = [1 if i > .5 else 0 for i in prediccion]\n",
    "metrics = metricas(validacion_label, prediccion)\n",
    "print(\"Prediccion Validacion\")\n",
    "[print(i) for i in metrics]\n",
    "print(skl.metrics.log_loss(validacion_label,prediccion))\n",
    "\n",
    "prediccion = modelo.predict(set_entrenamiento)\n",
    "prediccion = [1 if i > .5 else 0 for i in prediccion]\n",
    "metrics = metricas(entrenamiento_label, prediccion)\n",
    "print(\"Prediccion Train\")\n",
    "[print(i) for i in metrics]\n",
    "print(skl.metrics.log_loss(entrenamiento_label,prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(not MAXIMIZAR_HIPERPARAMETROS): sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_log_loss = 1000\n",
    "min_depth = 1000\n",
    "min_eta = 1000\n",
    "min_rondas = 1000\n",
    "rondas = 500\n",
    "min_early = 1000\n",
    "min_gamma = 1000\n",
    "for depth in range(2,5):\n",
    "    for eta in [0.1,0.3,0.5,0.7,0.9]:\n",
    "        for early in range(1,5):\n",
    "            for gamma in range(0,300,100):\n",
    "                parametros = {\"booster\":\"gbtree\", \"max_depth\":depth, \"eta\": eta, \"objective\": \"binary:logistic\", \"nthread\":2,\"gamma\":gamma}\n",
    "                modelo = xgb.train(parametros, set_entrenamiento, rondas, evaluacion,early_stopping_rounds = early)\n",
    "                prediccion = modelo.predict(set_validacion)\n",
    "                prediccion = [1 if i > .5 else 0 for i in prediccion]\n",
    "                log_loss = skl.metrics.log_loss(validacion_label,prediccion)\n",
    "                if (log_loss < min_log_loss):\n",
    "                    min_log_loss = log_loss\n",
    "                    min_depth = depth\n",
    "                    min_eta = eta\n",
    "                    min_rondas = rondas\n",
    "                    min_gamma = gamma\n",
    "                    min_early = early\n",
    "\n",
    "\n",
    "print(\"log: \",min_log_loss)                \n",
    "print(\"depth: \",min_depth)      \n",
    "print(\"eta: \",min_eta)    \n",
    "print(\"rondas\",min_rondas)\n",
    "print(\"gamma: \", min_gamma)\n",
    "print(\"early: \",min_early)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros = {\"booster\":\"gbtree\", \"max_depth\":min_depth, \"eta\": min_eta, \"objective\": \"binary:logistic\", \"nthread\":2,\"gamma\":min_gamma}\n",
    "modelo = xgb.train(parametros, set_entrenamiento, min_rondas, evaluacion,early_stopping_rounds = min_early)\n",
    "prediccion = modelo.predict(set_test)\n",
    "prediccion = [1 if i > .5 else 0 for i in prediccion]\n",
    "metrics = metricas(test_label, prediccion)\n",
    "print(\"Prediccion Test\")\n",
    "[print(i) for i in metrics]\n",
    "print(skl.metrics.log_loss(test_label,prediccion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
