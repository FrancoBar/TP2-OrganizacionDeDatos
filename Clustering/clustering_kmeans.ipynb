{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import catboost as cb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, log_loss\n",
    "import skopt\n",
    "import scipy\n",
    "from skopt.space import Real\n",
    "\n",
    "PREDICCION_REAL = False\n",
    "MAXIMIZAR_HIPERPARAMETROS = False\n",
    "PARAMETROS = {\n",
    "    'task_type' : 'GPU',\n",
    "    'devices' : '0:1',\n",
    "    'bootstrap_type' : 'MVS',\n",
    "    'has_time' : True,\n",
    "    \n",
    "    #\"rsm\" : 0.36719138525672734,\n",
    "    'bagging_temperature': 1.1063407351624084,\n",
    "    'border_count': 7137,\n",
    "    'depth': 5,\n",
    "    'early_stopping_rounds': 4,\n",
    "     'iterations': 7,\n",
    "    'l2_leaf_reg': 0.17260178161990627,\n",
    "    'learning_rate': 0.027307511040591478,\n",
    "    'random_seed': 5712,\n",
    "    'random_strength': 2.3464965049108726e-07,\n",
    "    'scale_pos_weight': 0.819600044656442,\n",
    "    'subsample': 0.9880746674599722\n",
    "}\n",
    "\n",
    "#No escala muy bien a partir del valor 12 \n",
    "N_CLUSTERS = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#APERTURA DE ARCHIVO DE ARCHIVOS\n",
    "entrenamiento = pd.read_pickle(\"../Archivos/Arboles_entrenamiento.pkl\")\n",
    "test = pd.read_pickle(\"../Archivos/Arboles_validacion.pkl\")\n",
    "\n",
    "if (PREDICCION_REAL):\n",
    "    entrenamiento = entrenamiento.append(test)\n",
    "    test = pd.read_pickle(\"../Archivos/Arboles_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILTRADO DE COLUMNAS - NO REMOVER STAGE O FECHA\n",
    "\n",
    "#columnas_fecha = ['Month','Last_Modified_Date','Account_Created_Date','Opportunity_Created_Date','Quote_Expiry_Date','Planned_Delivery_Start_Date','Planned_Delivery_End_Date']\n",
    "fugas = ['Sales_Contract_No','ID','Account_Name','Account_Owner','Opportunity_Owner','Last_Modified_By','ASP','ASP_(converted)']\n",
    "otros = ['Currency']\n",
    "\n",
    "entrenamiento = entrenamiento.drop(columns=fugas)\n",
    "test = test.drop(columns=fugas)\n",
    "\n",
    "#entrenamiento = entrenamiento.drop(columns=columnas_fecha)\n",
    "#test = test.drop(columns=columnas_fecha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FECHAS A DIAS\n",
    "\n",
    "columnas_fecha = ['Year-Month','Last_Modified_Date','Account_Created_Date','Opportunity_Created_Date','Quote_Expiry_Date','Planned_Delivery_Start_Date','Planned_Delivery_End_Date']\n",
    "def fecha_a_dias(x):\n",
    "    fecha_origen = pd.to_datetime('01/01/2000', format='%m/%d/%Y')\n",
    "    for columna in columnas_fecha:\n",
    "        x[columna] = x[columna].apply(lambda x : (x - fecha_origen).days)\n",
    "\n",
    "fecha_a_dias(entrenamiento)\n",
    "fecha_a_dias(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXTRACCION DE STAGE\n",
    "\n",
    "objetivo = entrenamiento['Stage']\n",
    "entrenamiento = entrenamiento.drop(columns=['Stage'])\n",
    "columnas_category = list(entrenamiento.select_dtypes(include=['category']).columns)\n",
    "if 'Stage' in columnas_category : columnas_category.remove('Stage')\n",
    "    \n",
    "if not PREDICCION_REAL:\n",
    "    test_label = test['Stage']\n",
    "    test = test.drop(columns=['Stage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIMPIEZA EXTRA PARA CLUSTERING\n",
    "import category_encoders\n",
    "\n",
    "def categoricas_a_numericas(train,test,label,usar_label):\n",
    "    if (usar_label):\n",
    "        columnas_object = list(train.select_dtypes(include=['category']).columns)\n",
    "    else:\n",
    "        columnas_object = list(test.select_dtypes(include=['category']).columns)\n",
    "    if 'Stage' in columnas_object : columnas_object.remove('Stage')\n",
    "    ohe = category_encoders.cat_boost.CatBoostEncoder(cols = columnas_object,return_df = True)\n",
    "    ohe.fit(train,label)\n",
    "    if (usar_label):\n",
    "        columnas = ohe.transform(train,label)\n",
    "        for columna in columnas_object:\n",
    "            train[columna] = columnas[columna].copy()\n",
    "    else:\n",
    "        columnas = ohe.transform(test)\n",
    "        for columna in columnas_object:\n",
    "            test[columna] = columnas[columna].copy()\n",
    "            \n",
    "categoricas_a_numericas(entrenamiento,test,objetivo,False)\n",
    "categoricas_a_numericas(entrenamiento,test,objetivo,True)\n",
    "\n",
    "def limpiar_nan(col,entrenamiento,test):\n",
    "    mean = entrenamiento[col].mean()\n",
    "    entrenamiento[col] = entrenamiento[col].replace(np.NaN,mean)\n",
    "    mean = test[col].mean()\n",
    "    test[col] = test[col].replace(np.NaN,mean)\n",
    "    \n",
    "def limpiar_inf(col,entrenamiento,test):\n",
    "    entrenamiento[col] = entrenamiento[col].replace(math.inf,np.NaN)\n",
    "    test[col] = test[col].replace(math.inf,np.NaN)\n",
    "    \n",
    "def limpiar_nan(col,entrenamiento,test):\n",
    "    mean = entrenamiento[col].mean()\n",
    "    entrenamiento[col] = entrenamiento[col].replace(np.NaN,mean)\n",
    "    mean = test[col].mean()\n",
    "    test[col] = test[col].replace(np.NaN,mean)\n",
    "    \n",
    "def limpiar_inf(col,entrenamiento,test):\n",
    "    entrenamiento[col] = entrenamiento[col].replace(math.inf,np.NaN)\n",
    "    test[col] = test[col].replace(math.inf,np.NaN)\n",
    "\n",
    "def limpiar(entrenamiento,test,limite):\n",
    "    for col in entrenamiento.columns:\n",
    "        ent_null = entrenamiento.loc[entrenamiento[col] == np.inf]\n",
    "        if (ent_null[col].count() > limite):\n",
    "            entrenamiento.drop(columns = [col],inplace=True)\n",
    "            test.drop(columns = [col],inplace=True)\n",
    "        if (0<ent_null[col].count() <= limite):\n",
    "            limpiar_inf(col,entrenamiento,test)        \n",
    "    for col in test.columns:\n",
    "        ent_null = test.loc[test[col] == np.inf]\n",
    "        if (ent_null[col].count() > limite):\n",
    "            entrenamiento.drop(columns = [col],inplace=True)\n",
    "            test.drop(columns = [col],inplace=True)\n",
    "        if (0<ent_null[col].count() <= limite):\n",
    "            limpiar_inf(col,entrenamiento,test)        \n",
    "\n",
    "    for col in entrenamiento.columns:\n",
    "        ent_null = entrenamiento.loc[entrenamiento[col].isnull()]\n",
    "        ent_null = ent_null.replace(np.NaN,0)\n",
    "        if (ent_null[col].count() > limite):\n",
    "            entrenamiento.drop(columns = [col],inplace=True)\n",
    "            test.drop(columns = [col],inplace=True)\n",
    "        if (0<ent_null[col].count() <= limite):\n",
    "            limpiar_nan(col,entrenamiento,test)        \n",
    "    for col in test.columns:\n",
    "        ent_null = test.loc[test[col].isnull()]\n",
    "        ent_null = ent_null.replace(np.NaN,0)\n",
    "        if (ent_null[col].count() > limite):\n",
    "            entrenamiento.drop(columns = [col],inplace=True)\n",
    "            test.drop(columns = [col],inplace=True)\n",
    "        if (0<ent_null[col].count() <= limite):\n",
    "            limpiar_nan(col,entrenamiento,test)\n",
    "\n",
    "limpiar(entrenamiento,test,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEPARACION EN CLUSTERS\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=N_CLUSTERS, random_state=0).fit(entrenamiento)\n",
    "kmeans.predict(entrenamiento)\n",
    "\n",
    "entrenamiento['Cluster'] = kmeans.predict(entrenamiento)\n",
    "test['Cluster'] = kmeans.predict(test)\n",
    "\n",
    "entrenamiento['Stage'] = objetivo\n",
    "test['Stage'] = test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6411\n",
       "6    5005\n",
       "3     454\n",
       "4     189\n",
       "2      18\n",
       "5       3\n",
       "1       1\n",
       "Name: Cluster, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entrenamiento['Cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3548\n",
       "6     762\n",
       "3     153\n",
       "4      50\n",
       "2       2\n",
       "Name: Cluster, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0:\n",
      "0:\tlearn: 0.6259457\ttest: 0.6832380\tbest: 0.6832380 (0)\ttotal: 38.8ms\tremaining: 233ms\n",
      "1:\tlearn: 0.5678271\ttest: 0.6747624\tbest: 0.6747624 (1)\ttotal: 76.8ms\tremaining: 192ms\n",
      "2:\tlearn: 0.5196699\ttest: 0.6667335\tbest: 0.6667335 (2)\ttotal: 119ms\tremaining: 159ms\n",
      "3:\tlearn: 0.4783762\ttest: 0.6588669\tbest: 0.6588669 (3)\ttotal: 162ms\tremaining: 122ms\n",
      "4:\tlearn: 0.4429015\ttest: 0.6518958\tbest: 0.6518958 (4)\ttotal: 207ms\tremaining: 82.9ms\n",
      "5:\tlearn: 0.4139174\ttest: 0.6451732\tbest: 0.6451732 (5)\ttotal: 269ms\tremaining: 44.9ms\n",
      "6:\tlearn: 0.3895762\ttest: 0.6391210\tbest: 0.6391210 (6)\ttotal: 313ms\tremaining: 0us\n",
      "bestTest = 0.6391210301\n",
      "bestIteration = 6\n",
      "Cluster 1:\n",
      "Cluster con pocos elementos o poca variedad de stage\n",
      "Cluster 2:\n",
      "0:\tlearn: 0.6341980\ttest: 0.6342828\tbest: 0.6342828 (0)\ttotal: 14.9ms\tremaining: 89.5ms\n",
      "1:\tlearn: 0.5803445\ttest: 0.5804907\tbest: 0.5804907 (1)\ttotal: 29.2ms\tremaining: 72.9ms\n",
      "2:\tlearn: 0.5296029\ttest: 0.5538787\tbest: 0.5538787 (2)\ttotal: 42.2ms\tremaining: 56.2ms\n",
      "3:\tlearn: 0.4860332\ttest: 0.5078974\tbest: 0.5078974 (3)\ttotal: 54.2ms\tremaining: 40.7ms\n",
      "4:\tlearn: 0.4453354\ttest: 0.4659840\tbest: 0.4659840 (4)\ttotal: 66.8ms\tremaining: 26.7ms\n",
      "5:\tlearn: 0.4083315\ttest: 0.4277952\tbest: 0.4277952 (5)\ttotal: 78.5ms\tremaining: 13.1ms\n",
      "6:\tlearn: 0.3747068\ttest: 0.3930241\tbest: 0.3930241 (6)\ttotal: 91.3ms\tremaining: 0us\n",
      "bestTest = 0.393024087\n",
      "bestIteration = 6\n",
      "Cluster 3:\n",
      "0:\tlearn: 0.6531779\ttest: 0.6755269\tbest: 0.6755269 (0)\ttotal: 15.6ms\tremaining: 93.8ms\n",
      "1:\tlearn: 0.6168907\ttest: 0.6594725\tbest: 0.6594725 (1)\ttotal: 33.7ms\tremaining: 84.3ms\n",
      "2:\tlearn: 0.5812702\ttest: 0.6485765\tbest: 0.6485765 (2)\ttotal: 50.7ms\tremaining: 67.7ms\n",
      "3:\tlearn: 0.5428019\ttest: 0.6307419\tbest: 0.6307419 (3)\ttotal: 66.4ms\tremaining: 49.8ms\n",
      "4:\tlearn: 0.5103762\ttest: 0.6244466\tbest: 0.6244466 (4)\ttotal: 81.7ms\tremaining: 32.7ms\n",
      "5:\tlearn: 0.4896062\ttest: 0.6168788\tbest: 0.6168788 (5)\ttotal: 94.6ms\tremaining: 15.8ms\n",
      "6:\tlearn: 0.4711050\ttest: 0.6079998\tbest: 0.6079998 (6)\ttotal: 106ms\tremaining: 0us\n",
      "bestTest = 0.6079997589\n",
      "bestIteration = 6\n",
      "Cluster 4:\n",
      "0:\tlearn: 0.6122844\ttest: 0.6327789\tbest: 0.6327789 (0)\ttotal: 12.9ms\tremaining: 77.7ms\n",
      "1:\tlearn: 0.5406342\ttest: 0.5794487\tbest: 0.5794487 (1)\ttotal: 26.4ms\tremaining: 66.1ms\n",
      "2:\tlearn: 0.4771453\ttest: 0.5325627\tbest: 0.5325627 (2)\ttotal: 39.6ms\tremaining: 52.8ms\n",
      "3:\tlearn: 0.4117507\ttest: 0.4794587\tbest: 0.4794587 (3)\ttotal: 52.2ms\tremaining: 39.1ms\n",
      "4:\tlearn: 0.3554242\ttest: 0.4330474\tbest: 0.4330474 (4)\ttotal: 63.9ms\tremaining: 25.5ms\n",
      "5:\tlearn: 0.3070696\ttest: 0.3926466\tbest: 0.3926466 (5)\ttotal: 75.7ms\tremaining: 12.6ms\n",
      "6:\tlearn: 0.2656576\ttest: 0.3576048\tbest: 0.3576048 (6)\ttotal: 87.8ms\tremaining: 0us\n",
      "bestTest = 0.3576047674\n",
      "bestIteration = 6\n",
      "Cluster 5:\n",
      "Cluster con pocos elementos o poca variedad de stage\n",
      "Cluster 6:\n",
      "0:\tlearn: 0.6568396\ttest: 0.6805962\tbest: 0.6805962 (0)\ttotal: 30.7ms\tremaining: 184ms\n",
      "1:\tlearn: 0.6244356\ttest: 0.6687977\tbest: 0.6687977 (1)\ttotal: 60.7ms\tremaining: 152ms\n",
      "2:\tlearn: 0.5958937\ttest: 0.6574183\tbest: 0.6574183 (2)\ttotal: 90.2ms\tremaining: 120ms\n",
      "3:\tlearn: 0.5707000\ttest: 0.6470892\tbest: 0.6470892 (3)\ttotal: 120ms\tremaining: 89.8ms\n",
      "4:\tlearn: 0.5531328\ttest: 0.6373006\tbest: 0.6373006 (4)\ttotal: 150ms\tremaining: 59.8ms\n",
      "5:\tlearn: 0.5328222\ttest: 0.6278188\tbest: 0.6278188 (5)\ttotal: 180ms\tremaining: 29.9ms\n",
      "6:\tlearn: 0.5143149\ttest: 0.6180993\tbest: 0.6180993 (6)\ttotal: 210ms\tremaining: 0us\n",
      "bestTest = 0.6180992811\n",
      "bestIteration = 6\n"
     ]
    }
   ],
   "source": [
    "#DIVISION\n",
    "\n",
    "model = []\n",
    "preds = []\n",
    "slice_entrenamiento = []\n",
    "slice_test = []\n",
    "slice_stage_entrenamiento = []\n",
    "slice_stage_test = []\n",
    "\n",
    "for i in range (0, N_CLUSTERS):\n",
    "    print(\"Cluster \" + str(i) + \":\")\n",
    "    \n",
    "    slice_entrenamiento.append(entrenamiento[entrenamiento['Cluster'] == i].copy())\n",
    "    slice_test.append(test[test['Cluster'] == i].copy())\n",
    "    \n",
    "    slice_entrenamiento[i] = slice_entrenamiento[i].drop(columns='Cluster')\n",
    "    slice_test[i] = slice_test[i].drop(columns='Cluster')\n",
    "    \n",
    "    slice_stage_entrenamiento.append(slice_entrenamiento[i].pop('Stage'))\n",
    "    slice_stage_test.append(slice_test[i].pop('Stage'))\n",
    "    \n",
    "    es_ruido = pd.Series(slice_stage_entrenamiento[i]).mean() > 0.98 or pd.Series(slice_stage_entrenamiento[i]).mean() < 0.02\n",
    "    \n",
    "    \n",
    "    entrenamiento_pool = cb.Pool(slice_entrenamiento[i], slice_stage_entrenamiento[i])\n",
    "    if(es_ruido):\n",
    "        test_pool = cb.Pool(slice_test[i])\n",
    "    else:\n",
    "        test_pool = cb.Pool(slice_test[i], slice_stage_test[i])\n",
    "        \n",
    "    model.append(cb.CatBoostClassifier(**PARAMETROS))\n",
    "    \n",
    "    if(es_ruido):\n",
    "        preds.append(slice_stage_entrenamiento[i])\n",
    "        print(\"Cluster con pocos elementos o poca variedad de stage\")\n",
    "        continue\n",
    "    \n",
    "    model[i].fit(entrenamiento_pool, eval_set = test_pool)\n",
    "    preds.append(model[i].predict_proba(test_pool))\n",
    "    preds[i] =  pd.Series([p[1] for p in  preds[i]])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RECONSTRUCCION\n",
    "\n",
    "for i in range (1, N_CLUSTERS):\n",
    "    slice_test[0].append(slice_test[i])\n",
    "    preds[0].append(preds[i])\n",
    "    slice_stage_test[0].append(slice_stage_test[i])\n",
    "\n",
    "test = slice_test[0]\n",
    "preds =  preds[0]\n",
    "test_label = slice_stage_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6364916025890319\n"
     ]
    }
   ],
   "source": [
    "if not (PREDICCION_REAL):\n",
    "    print(log_loss(test_label, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fallar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-c761f0cce551>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfallar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'fallar' is not defined"
     ]
    }
   ],
   "source": [
    "fallar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = pd.DataFrame()\n",
    "resultados['Opportunity_ID'] = test['Opportunity_ID']\n",
    "resultados['Target'] = pd.Series(preds)\n",
    "resultados = resultados.groupby('Opportunity_ID').mean()\n",
    "resultados = resultados.reset_index()\n",
    "\n",
    "if not (PREDICCION_REAL):\n",
    "    resultados.to_csv(\"../Archivos/prediccion_cluster_validacion.csv\", index=False)\n",
    "else:\n",
    "    resultados.to_csv(\"../Archivos/prediccion_cluster_test.csv\", index=False)\n",
    "    \n",
    "resultados['Target'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
